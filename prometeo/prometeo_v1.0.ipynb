{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROMETEO_v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "import textwrap\n",
    "import tiktoken\n",
    "import umap.umap_ as umap\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain import PromptTemplate\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Cuenta el número de tokens en el documento\n",
    "    proporcionado.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def reduce_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Esta función no la comprendo. Estudie\n",
    "    para entenderla.\"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "def get_optimal_clusters(embeddings: np.ndarray, max_clusters: int = 50, random_state: int = 1234):\n",
    "    \"\"\"Obtiene el número óptimo de clústers.\"\"\"\n",
    "    max_clusters = min(max_clusters, len(embeddings))\n",
    "    bics = [GaussianMixture(n_components=n, random_state=random_state).fit(embeddings).bic(embeddings)\n",
    "            for n in range(1, max_clusters)]\n",
    "    return np.argmin(bics) + 1\n",
    "\n",
    "def gmm_clustering(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"Clusteriza con el método GMM.\"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state).fit(embeddings)\n",
    "    probs = gm.predict_proba(embeddings)\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters\n",
    "\n",
    "def format_cluster_texts(df):\n",
    "    \"\"\"Agrupa los textos de cada clúster el listas.\"\"\"\n",
    "    clustered_texts = {}\n",
    "    for cluster in df['Cluster'].unique():\n",
    "        cluster_texts = df[df['Cluster'] == cluster]['Texto'].tolist()\n",
    "        clustered_texts[cluster] = \" --- \".join(cluster_texts)\n",
    "    return clustered_texts\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=80):\n",
    "    \"\"\"Formato para respuestas.\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    \"\"\"Generador de referencias.\"\"\"\n",
    "    print(wrap_text_preserve_newlines(llm_response['answer']))\n",
    "    print('\\nReferencias:')\n",
    "    for contexto in llm_response[\"context\"][:5]:\n",
    "        print(contexto)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "embeddings = OpenAIEmbeddings(\n",
    ")\n",
    "\n",
    "detailed_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-4o-mini'\n",
    ")\n",
    "\n",
    "template = \"\"\"Tu tarea es generar un resumen extremadamente detallado del siguiente\n",
    "texto: {text} \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | detailed_llm | StrOutputParser()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.5,\n",
    "    model_name='gpt-4o-mini'\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Quieres crear o cargar un tema de conversación?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elegiste crear de cero un tema de conversación.\n",
      "\n",
      "Número de tokens en el documento proporcionado: 8456\n",
      "\n",
      "Estás usando el tema de conversación: ascolfa_final_emb.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisr\\OneDrive\\Documentos\\GitHub\\1day_1thing\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\luisr\\OneDrive\\Documentos\\GitHub\\1day_1thing\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
      "c:\\Users\\luisr\\OneDrive\\Documentos\\GitHub\\1day_1thing\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K final es: 31\n",
      "\n",
      "\n",
      "Prometeo (1): Revisor bibliográfico.\n",
      "Yves (2): Diseñador de cartillas.\n",
      "Alan (3): Desarrollador de cartillas. \n",
      "Demós (4): Diseñador de presentaciones.\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"¿Crear (1) o cargar (2) un tema de conversación?: \")\n",
    "\n",
    "if user_input.lower() == \"1\":\n",
    "    print(f'Elegiste crear de cero un tema de conversación.\\n')\n",
    "\n",
    "    # Asegúrate de que haya PDFs en la carpeta 'docs'\n",
    "    documents = DirectoryLoader('./docs/', glob=\"./*.pdf\", loader_cls=PyPDFLoader).load()\n",
    "    # Tratameinto de caracteres indeseados\n",
    "    for d in documents:\n",
    "        d.page_content = d.page_content.replace('\\n', ' ').replace('\\t', ' ')\n",
    "\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "\n",
    "    d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "    d_reversed = list(reversed(d_sorted))\n",
    "    concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "        [doc.page_content for doc in d_reversed]\n",
    "    )\n",
    "    print(\n",
    "        \"Número de tokens en el documento proporcionado: %s\"\n",
    "        % num_tokens_from_string(concatenated_content)\n",
    "    )\n",
    "\n",
    "    global_embeddings = [embeddings.embed_query(txt) for txt in texts]\n",
    "\n",
    "    topic_name = input('¿Cómo se llama el tema de conversación?')\n",
    "\n",
    "    embed_name = topic_name + '_emb' + '.txt'\n",
    "    with open(rf'./{embed_name}', 'w') as f:\n",
    "        for i in global_embeddings:\n",
    "            f.write(\"%s\\n\" % i)\n",
    "    print(f'\\nEstás usando el tema de conversación: {embed_name}')\n",
    "\n",
    "    dim = 2\n",
    "    global_embeddings_reduced = reduce_cluster_embeddings(global_embeddings, dim)\n",
    "    labels, _ = gmm_clustering(global_embeddings_reduced, threshold=0.5)\n",
    "    simple_labels = [label[0] if len(label) > 0 else -1 for label in labels]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Texto': texts,\n",
    "        'Embedding': list(global_embeddings_reduced),\n",
    "        'Cluster': simple_labels\n",
    "    })\n",
    "\n",
    "    clustered_texts = format_cluster_texts(df)\n",
    "    summaries = {}\n",
    "    for cluster, text in clustered_texts.items():\n",
    "        summary = chain.invoke({\"text\": text})\n",
    "        summaries[cluster] = summary\n",
    "    embedded_summaries = [embeddings.embed_query(summary) for summary in summaries.values()]\n",
    "    embedded_summaries_np = np.array(embedded_summaries)\n",
    "    labels, _ = gmm_clustering(embedded_summaries_np, threshold=0.5)\n",
    "    simple_labels = [label[0] if len(label) > 0 else -1 for label in labels]\n",
    "    clustered_summaries = {}\n",
    "    for i, label in enumerate(simple_labels):\n",
    "        if label not in clustered_summaries:\n",
    "            clustered_summaries[label] = []\n",
    "        clustered_summaries[label].append(list(summaries.values())[i])\n",
    "    final_summaries = {}\n",
    "    for cluster, texts in clustered_summaries.items():\n",
    "        combined_text = ' '.join(texts)\n",
    "        summary = chain.invoke({\"text\": combined_text})\n",
    "        final_summaries[cluster] = summary\n",
    "    texts_from_df = df['Texto'].tolist()\n",
    "    texts_from_clustered_texts = list(clustered_texts.values())\n",
    "    texts_from_final_summaries = list(final_summaries.values())\n",
    "\n",
    "    combined_texts = texts_from_df + texts_from_clustered_texts + texts_from_final_summaries\n",
    "\n",
    "    file_name = topic_name + '.txt'\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        for t in combined_texts:\n",
    "            f.write(\"%s\\n\" % t)\n",
    "\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    textos = text_splitter.split_text(content)\n",
    "\n",
    "    persist_directory = topic_name + '_kb'\n",
    "    vectorstore = Chroma.from_texts(texts=textos,\n",
    "                                    embedding=embeddings,\n",
    "                                    persist_directory=persist_directory)\n",
    "    vectorstore.persist()\n",
    "    vectorstore = None\n",
    "    os.system(f'zip -r db.zip ./{persist_directory}')\n",
    "\n",
    "    vectorstore = Chroma(persist_directory=persist_directory,\n",
    "                         embedding_function=embeddings)\n",
    "\n",
    "    def adjust_final_number(string: str, max_threshold: int, initial_number: int) -> int:\n",
    "        final_number = initial_number\n",
    "        while final_number < max_threshold:\n",
    "            retriever = vectorstore.as_retriever(search_kwargs={\"k\": final_number})\n",
    "            docs = retriever.invoke(string)\n",
    "            text = \"\".join([doc.page_content for doc in docs])\n",
    "            if num_tokens_from_string(text) < max_threshold:\n",
    "                final_number += 1\n",
    "            else:\n",
    "                break\n",
    "        return final_number\n",
    "\n",
    "    final_number = adjust_final_number(\"¿Cuál es el tema principal del documento?\", 10000, 4)\n",
    "    print(f'\\nK final es: {final_number}')\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": final_number})\n",
    "    \n",
    "elif user_input.lower() == \"2\":\n",
    "    print('Elegiste cargar un tema de conversación ya creado.\\n')\n",
    "    global_embeddings = []\n",
    "\n",
    "    topic_name = input('¿Cómo se llama el tema de conversación?')\n",
    "\n",
    "    embed_name = topic_name + '_emb' + '.txt'\n",
    "    print(f'Estás usando el tema de conversación: {embed_name}\\n')\n",
    "    with open(rf'./{embed_name}', 'r') as f:\n",
    "        for i in f:\n",
    "            x = ast.literal_eval(i.strip())  # Convertir la cadena a lista de números\n",
    "            global_embeddings.append(x)\n",
    "\n",
    "    global_embeddings = np.array(global_embeddings, dtype=float)\n",
    "\n",
    "    file_name = topic_name + '.txt'\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    textos = text_splitter.split_text(content)\n",
    "\n",
    "    persist_directory = topic_name + '_kb'\n",
    "    vectorstore = Chroma(persist_directory=persist_directory, \n",
    "                    embedding_function=embeddings)\n",
    "\n",
    "    def adjust_final_number(string: str, max_threshold: int, initial_number: int) -> int:\n",
    "        final_number = initial_number\n",
    "        while final_number < max_threshold:\n",
    "            retriever = vectorstore.as_retriever(search_kwargs={\"k\": final_number})\n",
    "            docs = retriever.invoke(string)\n",
    "            text = \"\".join([doc.page_content for doc in docs])\n",
    "            if num_tokens_from_string(text) < max_threshold:\n",
    "                final_number += 1\n",
    "            else:\n",
    "                break\n",
    "        return final_number\n",
    "\n",
    "    final_number = adjust_final_number(\"¿Cuál es el tema principal del documento?\", 10000, 4)\n",
    "    print(f'K final es: {final_number}')\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": final_number})\n",
    "    \n",
    "elif user_input != \"1\" and user_input != \"2\":\n",
    "    print('No seleccionaste ningún tema de conversación.\\n')\n",
    "\n",
    "# Se personaliza el LLM #\n",
    "\n",
    "print('\\n\\nPrometeo (1): Revisor bibliográfico.\\nYves (2): Diseñador de cartillas.\\nAlan (3): Desarrollador de cartillas. \\nDemós (4): Diseñador de presentaciones.')\n",
    "\n",
    "template_select = input('Prometeo (1); Yves (2); Alan (3); Demós (4): ')\n",
    "\n",
    "if template_select == \"1\":\n",
    "\n",
    "    name = 'Prometeo'\n",
    "\n",
    "    template = \"\"\"\n",
    "    Eres Prometeo, un asistente personal especializado en revisión biliográfica que habla Español.\n",
    "    Tu tarea consiste en proporcionar respuestas extremadamente detalladas a cualquier tipo de \n",
    "    pregunta relacionada con el siguiente contexto obtenido de un artículo científico: {context}.\n",
    "\n",
    "    SIEMPRE debes responder en Español, con excepción de nombres propios.\n",
    "\n",
    "    NUNCA hables específicamente del contexto proporcionado.\n",
    "\n",
    "    NUNCA hables de ti a menos de que la pregunta lo requiera.\n",
    "\n",
    "    Teniendo en cuenta TODO lo anterior, responde la siguiente pregunta: {question}\n",
    "    \"\"\"\n",
    "\n",
    "elif template_select == \"2\":\n",
    "\n",
    "    name = 'Yves'\n",
    "\n",
    "    template = \"\"\"\n",
    "    Eres Yves, un asistente personal que habla Español, especializado en el diseño y desarrollo de cartillas \n",
    "    pedagógicas para estudiantes universitarios. Tu tarea consiste en ayudar a los estudiantes a identificar \n",
    "    información relevante del siguiente contexto obtenido de un artículo científico: {context}.\n",
    "\n",
    "    SIEMPRE debes responder en Español, con excepción de nombres propios.\n",
    "\n",
    "    NUNCA hables específicamente del contexto proporcionado.\n",
    "\n",
    "    NUNCA hables de ti a menos de que la tarea lo requiera.\n",
    "\n",
    "    Teniendo en cuenta TODO lo anterior, apoya al equipo con la siguiente tarea: {question}\n",
    "    \"\"\"\n",
    "\n",
    "elif template_select == \"3\":\n",
    "\n",
    "    name = 'Alan'\n",
    "\n",
    "    template = \"\"\"\n",
    "    Eres Alan, un asistente personal especializado en el diseño y desarrollo de cartillas pedagógicas\n",
    "    visuales para estudiantes universitarios. Tu tarea es generar una propuesta de material didáctico en \n",
    "    formato de historieta, que cubra el tema principal en el siguiente contexto: {context}. El contenido\n",
    "    para cada página debe generarse del contexto proporcionado.\n",
    "\n",
    "    Los requisitos y condiciones esperadas de la propuesta son: \n",
    "    \n",
    "    - Total de 10 páginas con explicación de conceptos clave.\n",
    "    - Muy gráfico y profesional.\n",
    "    - Combinar ilustraciones con información clave sobre el tema.\n",
    "    - Cada página debe mantener un equilibrio entre el contenido visual y la explicación de los conceptos.\n",
    "    - Tener recursos pedagógicos como \"tips\" o secciones de \"¿sabías qué?\" con información detallada.\n",
    "\n",
    "    SIEMPRE debes responder en Español, con excepción de nombres propios.\n",
    "\n",
    "    NUNCA hables específicamente del contexto proporcionado.\n",
    "\n",
    "    NUNCA hables de ti a menos de que la tarea lo requiera.\n",
    "\n",
    "    Teniendo en cuenta TODO lo anterior, apoya al usuario con la siguiente tarea: {question}\n",
    "    \"\"\"\n",
    "\n",
    "elif template_select == \"4\":\n",
    "\n",
    "    name = 'Demós'\n",
    "    \n",
    "    template = \"\"\"\n",
    "    Eres Demós, un asistente personal experto en la creación y diseño de presentaciones académicas para \n",
    "    investigadores y estudiantes universitarios. Tu tarea es desarrollar propuesta de presentación clara y efectiva \n",
    "    que aborde el tema del siguiente contexto: {context}. El contenido para cada diapositiva debe generarse \n",
    "    del contexto proporcionado.\n",
    "\n",
    "    Los requisitos y condiciones esperadas para la presentación son:\n",
    "\n",
    "    - Total de 10 diapositivas.\n",
    "    - Diseño profesional y visualmente atractivo.\n",
    "    - Incluir gráficos o ilustraciones relevantes que apoyen el contenido.\n",
    "    - Cada diapositiva debe equilibrar texto e imágenes, evitando la sobrecarga de información.\n",
    "    - Debe incluir secciones como \"Introducción\", \"Desarrollo del tema\", \"Conclusiones\", y \"Referencias\".\n",
    "    - Opcionalmente, puedes agregar diapositivas con \"Preguntas clave\" para facilitar la discusión.\n",
    "\n",
    "    SIEMPRE debes responder en Español, con excepción de nombres propios.\n",
    "\n",
    "    NUNCA hables específicamente del contexto proporcionado.\n",
    "\n",
    "    NUNCA hables de ti a menos que la tarea lo requiera.\n",
    "\n",
    "    Teniendo en cuenta TODO lo anterior, apoya al usuario con la siguiente tarea: {question}\n",
    "    \"\"\"\n",
    "\n",
    "else:\n",
    "    print('No seleccionaste ningún asistente.\\n')\n",
    "\n",
    "selected_prompt = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | selected_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ask_questions():\n",
    "#     while True:\n",
    "#         if template_select == \"1\":\n",
    "#             query = input(f\"¡Hola, soy {name}! ¿Qué pregunta tienes?: \")\n",
    "#             print(query)\n",
    "#             llm_response = rag_chain_with_source.invoke(query)\n",
    "#             process_llm_response(llm_response)\n",
    "#             print('\\n\\n')\n",
    "            \n",
    "#             another_question = input(\"¿Tienes otra pregunta? (s/n): \").strip().lower()\n",
    "#             if another_question != 's':\n",
    "#                 break\n",
    "#         elif template_select == \"2\":\n",
    "#             query = input(f\"¡Hola, soy {name}! ¿En qué te puedo servir?: \")\n",
    "#             print(query)\n",
    "#             llm_response = rag_chain_with_source.invoke(query)\n",
    "#             process_llm_response(llm_response)\n",
    "#             print('\\n\\n')\n",
    "            \n",
    "#             another_question = input(\"¿Te puedo servir en algo más? (s/n): \").strip().lower()\n",
    "#             if another_question != 's':\n",
    "#                 break\n",
    "#         else:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prompt: Genera un mapa mental con los puntos claves del documento.\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     ask_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prometeo_preguntas_meta = ['¿Cuál es el título original y traducido del artículo?',\n",
    "#                            '¿Quién o quiénes son los autores del artículo?',\n",
    "#                            '¿En qué año fue redactado el artículo?',\n",
    "#                            '¿En qué revista o medio fue publicado el artículo?',\n",
    "#                            '¿En qué país fue redactado el artículo?',\n",
    "#                            '¿Puedes generar una cita bibliográfica en formato APA del documento?',\n",
    "#                            '¿Puedes hacer un resumen muy breve y conciso del documento?',\n",
    "#                            '¿Cuál es el link al DOI del documento?'\n",
    "                  \n",
    "                  \n",
    "#                   #'¿Cuáles son las palabras clave de investigación mencionadas en el documento y traducidas al español, del artículo?'\n",
    "#                   #'¿Cuál es la idea principal de investigación?',\n",
    "#                   #'¿Cuál es el objetivo u objetivos de la investigación?',\n",
    "#                   #'¿Cuál es la metodología usada en la investigación?',\n",
    "#                   #'¿Cuáles fueron los resultados más importantes de la investigación?',\n",
    "#                   #'¿Los resultados cumplen los objetivos de investigación?',\n",
    "#                   #'¿Cómo puede aportar esta investigación al diseño, desarrollo y puesta en marcha de un laboratorio de investigación para el programa de Administración de Empresas en una universidad?'\n",
    "# ]\n",
    "\n",
    "# for p in prometeo_preguntas_meta:\n",
    "#     query = p\n",
    "#     print(query)\n",
    "#     llm_response = rag_chain_with_source.invoke(query)\n",
    "#     process_llm_response(llm_response)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prometeo_preguntas_ddl = ['¿Cómo clasificarías el contenido del documento: 1) Explicación de la importancia del diseño de laboratorios de investigación o 2) Hallazgos importantes sobre el diseño de laboratorios de investigación? ¿Por qué?',\n",
    "#                           'De manera resumida, ¿qué puede aportar el artículo para el diseño y desarrollo de un laboratorio de investigación para el programa de Administración en una universidad?',\n",
    "#                           '¿Puedes generar un cita en formato APA del documento?'\n",
    "# ]\n",
    "\n",
    "# for p in prometeo_preguntas_ddl:\n",
    "#     query = p\n",
    "#     print(query)\n",
    "#     llm_response = rag_chain_with_source.invoke(query)\n",
    "#     process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Demo clasi\n",
    "# ddl = '¿Cómo clasificarías el contenido del documento: 1) Contenido introductorio que explica la importancia del diseño de laboratorios de investigación o 2) Hallazgos importantes sobre el diseño de laboratorios de investigación? ¿Por qué?'\n",
    "# justi = '¿El contenido podría brindar soporte a la hipótesis que afirma que los graduados de la universidad no poseen las habilidades y competencias necesarias para enfrentarse al mercado laboral actual? Si lo hace, menciona el punto más importante para reforzar la idea.'\n",
    "# query = ddl\n",
    "# print(query)\n",
    "# llm_response = rag_chain_with_source.invoke(query)\n",
    "# process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prometeo_preguntas_pedagogia = ['¿Cuál es la idea principal del artículo?',\n",
    "#                                 '¿Cuáles son los puntos claves del artículo que me pueden ayudar a diseñar material pedagógico efectivo?',\n",
    "#                                 'Según el artículo, ¿qué características deberían tener los materiales pedagógicos efectivos?',\n",
    "#                                 '¿Puedes generar un cita en formato APA del documento?'\n",
    "# ]\n",
    "\n",
    "# for p in prometeo_preguntas_pedagogia:\n",
    "#     query = p\n",
    "#     print(query)\n",
    "#     llm_response = rag_chain_with_source.invoke(query)\n",
    "#     process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yves_tareas_ls = ['Menciona principios básicos relacionados con el Lean Startup.',\n",
    "#                   'Menciona ejemplos de aplicación práctica del Lean Startup',\n",
    "#                   'Menciona herramientas y métodos para la aplicación del Lean Startup.',\n",
    "#                   'Identifica errores que se deben evitar en el Lean Startup.',\n",
    "#                   '¿El documento incluye casos de éxito en el uso del Lean Startup? Menciónalos.',\n",
    "#                   'Dime ¿cómo puede aportar el artículo para el diseño de una cartilla pedagógica basada en Lean Startup?',\n",
    "#                   'Genera una cita en formato APA del documento.'\n",
    "# ]\n",
    "\n",
    "# for p in yves_tareas_ls:\n",
    "#     query = p\n",
    "#     print(query + '\\n')\n",
    "#     llm_response = rag_chain_with_source.invoke(query)\n",
    "#     process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if template_select == '1':\n",
    "#     query = input(\"Hazme una pregunta: \")\n",
    "#     print(query + '\\n')\n",
    "#     llm_response = rag_chain_with_source.invoke(query)\n",
    "#     process_llm_response(llm_response)\n",
    "# elif template_select == \"2\":\n",
    "#     query = input(\"¿Cuál es mi tarea?: \")\n",
    "#     print(query + '\\n')\n",
    "#     llm_response = rag_chain_with_source.invoke(query)\n",
    "#     process_llm_response(llm_response)\n",
    "# elif template_select == \"3\":\n",
    "#     query = input(\"¿Cuál es mi tarea?: \")\n",
    "#     print(query + '\\n')\n",
    "#     llm_response = rag_chain_with_source.invoke(query)\n",
    "#     process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Puedes desarrollar los resultados esperados del documento, basado en lo siguiente: Se espera que la investigación identifique y categorice las herramientas de IA más efectivas que pueden ser implementadas en el proceso de aprendizaje y en el desarrollo de proyectos de emprendimiento. Esto incluirá un análisis de sus funcionalidades, ventajas y desventajas en el contexto educativo y empresarial.\n",
      "\n",
      "Los resultados esperados de la investigación se centran en la identificación y\n",
      "categorización de herramientas de inteligencia artificial (IA) que pueden ser\n",
      "efectivas en el ámbito del aprendizaje y el desarrollo de proyectos de\n",
      "emprendimiento. Este análisis se llevará a cabo a través de un enfoque\n",
      "sistemático que contemple diversas dimensiones de estas herramientas.\n",
      "\n",
      "1. **Identificación de Herramientas de IA**: Se anticipa que la investigación\n",
      "proporcionará una lista exhaustiva de las herramientas de IA más relevantes y\n",
      "utilizadas en el contexto educativo y empresarial. Esto incluirá tanto\n",
      "herramientas de software como plataformas que faciliten la enseñanza, la gestión\n",
      "de proyectos y el análisis de datos.\n",
      "\n",
      "2. **Clasificación por Funcionalidades**: Las herramientas identificadas serán\n",
      "clasificadas según sus funcionalidades específicas. Esto podría incluir:\n",
      "   - **Análisis de Datos**: Herramientas que permiten recopilar y analizar\n",
      "grandes volúmenes de información para la toma de decisiones informadas.\n",
      "   - **Automatización de Tareas**: Aplicaciones que ayudan a automatizar tareas\n",
      "repetitivas, liberando tiempo para actividades más estratégicas.\n",
      "   - **Personalización del Aprendizaje**: Sistemas que adaptan el contenido\n",
      "educativo a las necesidades individuales de los estudiantes, mejorando la\n",
      "experiencia de aprendizaje.\n",
      "   - **Generación de Contenido**: Herramientas que facilitan la creación de\n",
      "materiales educativos o de marketing, optimizando el proceso de desarrollo de\n",
      "productos.\n",
      "\n",
      "3. **Análisis de Ventajas y Desventajas**: Se espera que el estudio proporcione\n",
      "un análisis detallado de las ventajas y desventajas de cada herramienta. Esto\n",
      "incluirá:\n",
      "   - **Ventajas**:\n",
      "     - Mejora en la eficiencia operativa.\n",
      "     - Aumento en la capacidad de análisis y toma de decisiones.\n",
      "     - Personalización y adaptación a las necesidades de los usuarios.\n",
      "     - Optimización de recursos y reducción de costos.\n",
      "   - **Desventajas**:\n",
      "     - Dependencia de la tecnología y posibles problemas de accesibilidad.\n",
      "     - Riesgos asociados con la privacidad y la ética en el uso de datos.\n",
      "     - Necesidad de capacitación y adaptación por parte de los usuarios para\n",
      "maximizar el uso de estas herramientas.\n",
      "\n",
      "4. **Contextualización en el Ámbito Educativo y Empresarial**: Los resultados\n",
      "incluirán un examen de cómo estas herramientas se integran en los entornos\n",
      "educativos y empresariales. Se espera que se analicen casos específicos de\n",
      "implementación y se evalúe su impacto en la enseñanza y el emprendimiento,\n",
      "considerando factores como la cultura organizacional y la infraestructura\n",
      "tecnológica disponible.\n",
      "\n",
      "5. **Recomendaciones para la Implementación**: Finalmente, se anticipa que el\n",
      "estudio ofrecerá recomendaciones prácticas sobre cómo implementar eficazmente\n",
      "estas herramientas en el proceso de aprendizaje y en el desarrollo de proyectos\n",
      "de emprendimiento. Esto incluirá sugerencias sobre capacitación, integración con\n",
      "metodologías existentes y evaluación continua de su efectividad.\n",
      "\n",
      "En resumen, los resultados esperados de la investigación no solo identificarán y\n",
      "categorizarán las herramientas de IA más efectivas, sino que también\n",
      "proporcionarán un análisis crítico de sus funcionalidades, ventajas y\n",
      "desventajas, así como recomendaciones para su implementación en contextos\n",
      "educativos y empresariales.\n",
      "\n",
      "Referencias:\n",
      "page_content='y analizar cómo  las herramientas de IA pueden facilitar y optimizar el desarrollo de proyectos de  emprendimiento en el contexto universitario, identificando las oportunidades que  brindan estas herramientas tecnológicas y los posibles impactos al implementarlas  las diferentes etapas claves del emprendimiento. Ya que, la falta de un  entendimiento claro sobre estas dinámicas podría limitar la capacidad de los  emprendedores para aprovechar plenamente el potencial de la IA, lo que a su vez  podría afectar negativamente la competitividad y sostenibilidad de los nuevos  negocios en el mercado que se enfrenta a la nueva era digital. La creciente adopción de IA en diversos sectores ha generado un gran interés en  comprender su impacto y oportunidades en el ámbito del emprendimiento. Si bien  se reconoce el potencial de la IA para facilitar y acelerar la creación de nuevos  emprendimientos, aún existe una brecha en la comprensión sistemática de cómo  estas tecnologías pueden optimizar procesos clave como la planificación'\n",
      "page_content='y analizar cómo  las herramientas de IA pueden facilitar y optimizar el desarrollo de proyectos de  emprendimiento en el contexto universitario, identificando las oportunidades que  brindan estas herramientas tecnológicas y los posibles impactos al implementarlas  las diferentes etapas claves del emprendimiento. Ya que, la falta de un  entendimiento claro sobre estas dinámicas podría limitar la capacidad de los  emprendedores para aprovechar plenamente el potencial de la IA, lo que a su vez  podría afectar negativamente la competitividad y sostenibilidad de los nuevos  negocios en el mercado que se enfrenta a la nueva era digital. La creciente adopción de IA en diversos sectores ha generado un gran interés en  comprender su impacto y oportunidades en el ámbito del emprendimiento. Si bien  se reconoce el potencial de la IA para facilitar y acelerar la creación de nuevos  emprendimientos, aún existe una brecha en la comprensión sistemática de cómo  estas tecnologías pueden optimizar procesos clave como la planificación'\n",
      "page_content='Esta combinación de métodos permite una triangulación de datos, enriqueciendo el análisis y proporcionando una comprensión más profunda del papel de la IA en la educación y el emprendimiento.\\n\\n**5. Resultados Esperados:**\\nSe anticipa que el estudio proporcionará insights sobre el uso efectivo de la IA en el contexto educativo y emprendedor, así como recomendaciones para su implementación en el semillero de emprendimiento e innovación.\\n\\n**6. Conclusión:**\\nEl trabajo destaca la relevancia de la IA como motor de cambio en la educación superior y el emprendimiento, sugiriendo que su integración puede mejorar el aprendizaje y fomentar la innovación y la creación de empresas en el entorno universitario.\\n\\n**7. Palabras Clave:**\\nInteligencia artificial, Emprendimiento, Pedagogía, Transformación digital.\\n\\n**8. Introducción Detallada:**\\nLa IA se presenta como un fenómeno tecnológico transformador en diversos sectores, incluyendo la educación. Su uso ha crecido significativamente, obligando a las instituciones de educación superior a replantear cómo preparan a los estudiantes para el futuro laboral. La IA no solo transforma la enseñanza, sino que también influye en el desarrollo de habilidades emprendedoras.\\n\\n**9. Metodología Propuesta:**\\nLa investigación se basa en un enfoque cualitativo mixto, combinando técnicas de recolección de datos para obtener una visión integral sobre la aplicación de la IA en el emprendimiento.\\n\\n**10. Conclusión:**\\nLa investigación busca identificar oportunidades que la IA presenta en el emprendimiento y evaluar su efectividad en procesos críticos. La integración de la IA en la educación superior y en la incubación de emprendimientos es cada vez más relevante, planteando un desafío y una oportunidad para las instituciones educativas.'\n",
      "page_content='**1. Introducción y Contexto:**\\nEl documento es una ponencia de investigación presentada por académicos de la Universidad Nacional de Colombia, sede Palmira, que explora el impacto de la inteligencia artificial (IA) en la educación y el emprendimiento universitario. Los autores, Adriana Yisela Ruano Zuñiga, Angela Maria Tafur Escobar, Luis Enrique Riascos Oliveros y Alexandra Eugenia Arellano Guerrero, argumentan que la IA está revolucionando la enseñanza y el desarrollo de proyectos emprendedores, especialmente en el semillero de emprendimiento e innovación de la universidad.\\n\\n**2. Justificación:**\\nLa IA se presenta como una herramienta clave para mejorar el aprendizaje y fomentar la innovación en el ámbito universitario. El estudio se centra en cómo la IA puede optimizar el proceso de enseñanza y el desarrollo de emprendimientos, abordando la necesidad de preparar a los estudiantes para un futuro laboral en un entorno digital.\\n\\n**3. Objetivos del Estudio:**\\nEl principal objetivo es identificar las oportunidades que ofrece la IA y analizar su impacto en la creación de emprendimientos. Se evalúa la efectividad de la IA en procesos clave como:\\n- **Planificación Estratégica:** Definición de objetivos y estrategias.\\n- **Desarrollo de Productos:** Creación y mejora de productos.\\n- **Marketing:** Estrategias de marketing impulsadas por IA.\\n- **Captación de Clientes:** Métodos para atraer y retener clientes.\\n- **Ventas:** Optimización del proceso de ventas.\\n\\n**4. Metodología:**\\nSe propone una metodología cualitativa mixta que incluye:\\n- **Entrevistas:** Recopilación de información de expertos y participantes.\\n- **Grupos de Enfoque:** Discusiones grupales para obtener diversas perspectivas.\\n- **Análisis de Documentos:** Revisión de literatura relevante.\\n- **Observación:** Estudio de casos en el entorno universitario.\\n- **Encuestas Estructuradas:** Recolección de datos cuantitativos.'\n",
      "page_content='Además, argumenta que estas tecnologías no solo están  facilitando el surgimiento de nuevos emprendimientos, sino que también están  modificando de manera significativa los procesos y modelos de negocios  tradicionales.Este trabajo es clave para comprender la profunda interrelación entre  las tecnologías digitales y el emprendimiento, mostrando cómo la adopción y  adaptación de estas herramientas puede redefinir el éxito empresarial en la era  digital. El documento de Winkler , C. et al. (2023), ofrece un marco conceptual que puede  guiar los objetivos y resultados de aprendizaje, además de preguntas de  investigación que fomentan la discusión y el desarrollo de proyectos. También se  destacan aplicaciones prácticas y se abordan tanto los desafíos como las  oportunidades de la IA, incluyendo consideraciones éticas y la necesidad de  innovación en métodos de enseñanza. Finalmente, el documento subraya la  importancia de evaluar la efectividad de estas herramientas, garantizando un  enfoque integral en la educación sobre IA.'\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ACT ASCOLFA ###\n",
    "\n",
    "if template_select == '1':\n",
    "    query = input(\"Hazme una pregunta: \")\n",
    "    print(query + '\\n')\n",
    "    llm_response = rag_chain_with_source.invoke(query)\n",
    "    process_llm_response(llm_response)\n",
    "elif template_select == \"2\":\n",
    "    query = input(\"¿Cuál es mi tarea?: \")\n",
    "    print(query + '\\n')\n",
    "    llm_response = rag_chain_with_source.invoke(query)\n",
    "    process_llm_response(llm_response)\n",
    "elif template_select == \"3\":\n",
    "    query = input(\"¿Cuál es mi tarea?: \")\n",
    "    print(query + '\\n')\n",
    "    llm_response = rag_chain_with_source.invoke(query)\n",
    "    process_llm_response(llm_response)\n",
    "elif template_select == \"4\":\n",
    "    query = input(\"¿Cuál es mi tarea?: \")\n",
    "    print(query + '\\n')\n",
    "    llm_response = rag_chain_with_source.invoke(query)\n",
    "    process_llm_response(llm_response)\n",
    "else:\n",
    "    print(\"Para realizar una petición, primero debes seleccionar una asistente.\")\n",
    "\n",
    "## ¿Cómo puede aportar el documento a una propuesta de investigación para el diseño de un curso sobre herramientas de inteligencia artificial?\n",
    "# ¿Puedes generar una cita en formato APA del documento?\n",
    "# ¿El documento puede aportar a la definición de 'herramientas de inteligencia artificial'? Dime la definición en un párrafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cirjevskis, A. (2022). Exploring Coupled Open Innovation for Digital Servitization in Grocery Retail: From Digital Dynamic Capabilities Perspective. *Journal of Risk and Financial Management*, 15(9), 411. https://doi.org/10.3390/jrfm15090411\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## UNWRAPER ###\n",
    "###############\n",
    "\n",
    "wrapped_text = input('Ingresa el texto a desenvolver: ')\n",
    "unwrapped_text = textwrap.fill(wrapped_text, width=10000)\n",
    "pyperclip.copy(unwrapped_text)\n",
    "print(unwrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#busque caracteristicas\n",
    "\n",
    "\n",
    "¿Cuáles son los puntos claves del artículo que me pueden ayudar a diseñar una cartilla pedagógica basada en 'Lean Startup' como tema principal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacer historial y guardar conversaciones para medir efectividad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
