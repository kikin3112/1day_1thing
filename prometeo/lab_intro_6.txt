Co-Lab: research and development of an online learning environment for collaborative scientiﬁc discovery learning Wouter R. van Joolingena,b,*, Ton de Jongb, Ard W. Lazonderb, Elwin R. Savelsbergha, Sarah Manloveb aGraduate School of Teaching and Learning, University of Amsterdam, Wibautstraat 2-4, 1091 GM Amsterdam, The Netherlands bDepartment of Instructional Technology, University of Twente, The Netherlands Available online 8 December 2004 Abstract There are many design challenges that must be addressed in the development of collabora- tive scientiﬁc discovery learning environments. This contribution presents an overview of howthese challenges were addressed within Co-Lab, a collaborative learning environment in whichgroups of learners can experiment through simulations and remote laboratories, and express acquired understanding in a runnable computer model. Co-Lab /C213s architecture is introduced and explicated from the perspective of addressing typical problem areas for students withincollaborative discovery learning. From this view the processes of collaboration, inquiry, and modeling are presented with a description of how they have been supported in the past and how they are supported within Co-Lab /C213s design and tools. Finally, a research agenda is proposed for collaborative discovery learning with the Co-Lab environment. /C2112004 Elsevier Ltd. All rights reserved. Keywords: Collaborative learning; Inquiry learning; Learning environments; Dynamic modeling 0747-5632/$ - see front matter /C2112004 Elsevier Ltd. All rights reserved. doi:10.1016/j.chb.2004.10.039*Corresponding author. E-mail address: w.r.vanjoolingen@uva.nl (W.R. van Joolingen).Computers in Human Behavior 21 (2005) 671–688 www.elsevier.com/locate/comphumbehComputers in Human Behavior
1. Introduction Socio-constructivist learning theories perceive learning as a constructive, situated and collaborative process. These theories converge on the notion that learners developunderstanding of a domain by working on authentic tasks in realistic settings. Task performance preferably occurs in collaboration with peers, and should be regulated by the learners (instead of the teacher or the learning material). In science education, these notions of learning can be implemented by letting learners ‘‘act like scientists’’. That is, learners should perform experiments to dis-cover relationships between phenomena, and construct models to express theirunderstanding. Clearly, these learning activities are more constructive by naturethan, for instance, listening to lectures or solving paper-and-pencil physics problems.Experimentation and modeling are also authentic activities that reﬂect the way sci- entists go about in studying unknown phenomena. Learners thus develop domain knowledge and, at the same time, familiarize themselves with a scientist /C213s way of working and thinking (cf. Brown, Collins, & Duguid, 1989 ). Such enculturation can be further enhanced through collaboration. Teamwork has long since been acommon practice in science and many scientiﬁc discoveries were a joint eﬀort ( Dun- bar, 2001 ). Organizing science education around collaborative inquiry and modeling activi- ties requires innovative, student-centered forms of instructional support. Collabora- tive discovery learning environments are a potentially powerful means to oﬀer this type of support, provided that their design meets certain criteria. One obvious de-mand concerns the presence of tools learners can use to explore a task domainthrough experimentation. Yet merely doing experiments does not capture the fullrange of scientists /C213activities, nor will it develop deeply rooted, transferable knowl- edge and skills. Structural changes in domain knowledge require reﬂection in con-junction
knowl- edge and skills. Structural changes in domain knowledge require reﬂection in con-junction with modeling, and reﬂection is a natural component of the socialinteraction that occurs in collaboration ( Penner, 2001 ). Collaborative discovery learning environments should therefore comprise tools that support inquiry through experimentation, domain modeling and student collaboration. This article exempliﬁes how this type of support might be brought about. It does so by articulating the design considerations for Co-Lab, a learning environment inwhich groups of learners can experiment through simulations and remote laborato-ries, and express acquired understanding in a runnable computer model. The nextsection presents an overview of Co-Lab /C213s basic architecture. The sections that follow elucidate how the processes of inquiry, modeling and collaboration are supported within the environment and its tools. In the ﬁnal section, a research agenda is pro- posed for collaborative discovery learning with the Co-Lab learning environment. 2. The structure of Co-Lab learning environments Co-Lab supports collaborative discovery learning in the natural sciences at the upper secondary level and the ﬁrst years in university. Content is currently available672 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
for four domains: water management, greenhouse eﬀect, mechanics and electricity. Water management and greenhouse eﬀect are extensive courses that cover the rich-ness of these interdisciplinary domains. Both courses comprise several modules ofdiﬀerent levels of complexity. A building metaphor was used to elucidate this multi-level structure. Learners have access to one or more buildings symbolizing the courses in the various domains. Each building contains multiple ﬂoors (representing the modules) and each ﬂoor hasmultiple rooms to structure the learners /C213activities. Experimenting and modeling are supported in the Lab and Theory room, respectively. The Meeting room is intendedfor planning and monitoring; the Hall is where learners gather and collect theirassignment. Buildings and ﬂoors thus organize the domain, rooms organize thelearning activities. Fig. 1 shows the Co-Lab interface that appears upon entering a ﬂoor. The top- right part of the screen is the main working area. Here students can select various tools for experimentation and modeling. In keeping with the building metaphor, dif-ferent tools are available in diﬀerent rooms, so the content of this part of the screendepends on the learner /C213s current location. The left-hand side of the screen houses generic tools for navigation and collabo- ration as well as a tool to move learning objects across rooms. This part of the screenremains unchanged when students switch rooms, making its tools available in allrooms. The same is true for the bottom part of the screen where a synchronized chat tool supports communication. Fig. 1. Annotated screenshot of Co-Lab /C213s interface.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 673
3. Co-Lab /C213s collaborative discovery learning orientation In collaborative discovery learning, groups of students examine scientiﬁc phenom- ena and express their shared understanding in a runnable computer model. Learnersthus engage in three analytically distinct processes, namely inquiry, modeling and collaboration. However, in Co-Lab the demarcation between these processes is less clear cut. Collaboration, for instance, runs as a continuous thread through the dis-covery learning process, aﬀecting the way in which inquiry and modeling processesare performed and should be supported. Furthermore, modeling is integral to theinquiry process. Learners express their initial understanding of scientiﬁc phenomenain a model sketch, which is then used to predict and explain what will occur in thephenomena being modeled. By testing these hypotheses with the simulation or theremote lab, learners gain knowledge they can use to reﬁne or extend their model. The sections below detail Co-Lab /C213s orientation to collaborative discovery learn- ing. The processes of inquiry, modeling, and collaboration are described in separatesections, despite the dynamic interplay between them. 4. Facilitating inquiry learning Inquiry learning pertains to the acquisition of knowledge by a learner-regulated process of data collection and data interpretation. The inferential processes that build upon the data gathered by the learner should lead to the discovery of rules thatgovern the relations between variables in a given domain. This means that inquirylearning has shifted from the discovery of concepts (as it was originally conceivedin Gestalt psychology and the work of Bruner (1961) ) to discovery of rules ( De Jong & Van Joolingen, 1998 ). In Co-Lab, learners can collect data from built-in simulations, remote laboratories and remote databases. Regardless of the type of data source, learners are to unravel the relations between input and output variables through systematic experimentation.
are to unravel the relations between input and output variables through systematic experimentation. This process proceeds through ﬁve phases: analysis, hypothesis generation, experimentdesign, data interpretation, and conclusion. Njoo and De Jong (1993) coined the term transformative processes to indicate that the learners /C213activities in these phases are per- formed for the sole purpose of yielding knowledge. Regulatory processes , in contrast, serve to manage and control the inquiry learning process. Planning, monitoring andevaluation are typical instances of regulatory processes. A review by De Jong and Van Joolingen (1998) has produced a comprehensive overview of the diﬃculties learners encounter in inquiry learning. How these prob- lems were addressed in Co-Lab is discussed in the sections below. 4.1. Support for transformative processes4.1.1. Hypothesis generation One of the most pertinent problems in inquiry learning is formulating syntacti- cally correct (i.e., testable) hypotheses. One solution is to provide learners with674 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
partly speciﬁed hypotheses. Van Joolingen and De Jong (1993) introduced a hypoth- esis scratchpad which contained templates to formulate syntactically correct predic-tions. Learners could select a statement from a pull-down menu and complete it byadding variables, relations and condition. Unfortunately, usability problems pre-vented learners from taking full advantage of this tool. Bearing these problems in mind, Gijlers and De Jong (2004) converted the ideas of the hypotheses scratchpad into a proposition table. This tool comprised a list of fullyspeciﬁed hypotheses, the students /C213beliefs about a hypothesis and their willingness to test it (the proposition table was used in a collaborative setting). Students using theproposition table outperformed both the hypotheses scratchpad and the controlgroup on a test measuring intuitive knowledge. Protocol analysis revealed that thesediﬀerences arose because students in the proposition table group produced morestatements about hypothesis generation and discussed a larger number of hypotheses. Despite these favorable results, oﬀering fully speciﬁed hypotheses has the poten- tial disadvantage of revealing the key variables and relations to the learner. Thismight cause learners to skip the analysis phase and start experimenting on the basisof patchy knowledge. Co-Lab supports hypothesis construction in a graphical in-stead of a verbal way, using the built-in modeling tool in order to restrain learnersfrom jumping the gun. Learners use their model to express their propositions abouta relation between two variables. During the initial stages, pre-speciﬁed, qualitative relations can be selected from a drop-down menu. Hypotheses can be tested by com- paring the outcomes of the model with the simulation /C213s output. During the later stages, qualitative relations can gradually be replaced by quantitative ones, usingscientiﬁc formulas. 4.1.2. Experiment design Another class of problems pertains to the design of experiments.
formulas. 4.1.2. Experiment design Another class of problems pertains to the design of experiments. These include the design of inconclusive experiments, ineﬃcient experimentation behavior, and the de- sign of experiments that are not intended to test a hypothesis. Inconclusive experiments often arise because learners vary too many variables at once. Experimentation hints such as ‘‘vary only one variable at a time’’ can improvelearners /C213experimentation behavior in this respect ( De Jong & Van Joolingen, 1998 ). In Co-Lab, such hints are oﬀered in the Process Coordinator and in help ﬁles. Ineﬃcient experimentation occurs when learners fail to design informative experiments or when they repeat previous experiments. The former may be diﬃ-cult to overcome because inquiry learning essentially is a learner-directed process. Repetitions on the other hand might be avoided by providing insight into the experiments a learner has already performed. To this end, SimQuest ( Van Joolin- gen & De Jong, 2003 ) simulations contain a monitoring tool that shows the initial values of input variables and end values of output variables for each experiment(Veermans, 2002 ). Learners can reveal the progress of output variables across time by selecting a given experiment from the tool and clicking the /C212replay /C213but- ton. The simulation is then run using the exact same settings as in the originalexperiment.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 675
Experimentation support in Co-Lab is more output-oriented in that learners can save experimental results instead of experimental settings. Learners can save tablesand graphs in the Object Repository and annotate these to identify the settings usedin the experiment. Tables and graphs can be retrieved by clicking the /C212restore /C213button (seeFig. 1 ). Designing experiments that are not intended to test hypotheses can be indicative of an engineering approach .Schauble, Klopfer, and Raghavan (1991) characterize this approach as one in which learners attempt to create a desirable outcome in-stead of trying to understand the model. Co-Lab seeks to resolve this problemby requiring learners to produce a comprehensive model. Assignments in Co-Labare therefore open-ended, merely instructing learners to come to grips with a phe-nomenon and model it. However, research suggests that additional experimenta-tion hints are needed. An exploratory study with Co-Lab revealed that experimentation in absence of any further support to the contrary shows learners engaging in an engineering approach ( Manlove & Lazonder, 2004 ). Learners merely used the water tank simulation (displayed in Fig. 1 ) to reach equilibrium through trial-and-error. Once they succeeded, they did not try to discover the sim-ulation /C213s underlying model by reaching equilibrium using diﬀerent settings (as suggested in the text of the assignment). 4.2. Data interpretation Learners often experience diﬃculties in drawing conclusions from their data. Visual- izing data is a well-tried solution. A linear relationship between two variables can, forinstance, more easily be identiﬁed from a graph than from numerical values in a table.Nevertheless the construction and interpretation of graphs appears to be both time con-suming and error prone. Co-Lab /C213s graph tool therefore automatically generates a graph whenthesimulationisrun.Learnerscanthusreadilyinterprettheresultswithouthavingto convert raw data into a graph.
convert raw data into a graph. Co-Lab does support across-experiment comparison of data by allowing the learner to compare the plots of the results of more than one experiment in onegraph. An interesting extension could be to add the extended version of Veer- mans /C213(2002) monitoring tool to the Co-Lab environment which allows learners to arrange stored experiments according to one of the variables to compare var-ious experiments. Between experiment comparison is further supported by agraphing option that allows learners to plot the end value of an output variableobtained in a series of experiments in a single graph. This option supports learn- ers in performing a meta-analysis of their own data to extrapolate relations between variables. 4.3. Support for regulatory processes Regulatory processes are pivotal to successful inquiry learning. While constructiv- ists advocate that learners should independently engage regulatory activities such asplanning, monitoring and evaluation, research has consistently shown that addi-676 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
tional support is needed for learners to become ‘‘active agents of their own inquiry learning’’ ( Kluwe, 1982 ). Task complexity can get in the way of learners /C213spontaneous use of self-regulatory skills ( Elshout, 1987 ). This problem might be overcome by scaﬀolding the inquiry process along a spectrum of progression. This so-called model progression allows learners to start with a simpliﬁed version of the simulation; complexity is gradually increased by introducing new variables or features during the course of the learningprocess ( De Jong & Van Joolingen, 1998 ). In Co-Lab, the ﬂoors within a building represent the various levels of complexity. To illustrate, model progression in thewater management building develops from a simulation of a water tank, througha real water tank (accessible via a remote lab), to an advanced simulation of poldersand rivers that includes tidal movement, rainfall, and pumping stations. While model progression enables learners to employ existing self-regulatory skills, it does not cater for the use of unmastered skills. To provide the latter type of sup- port, speciﬁc features or tools are implemented in the learning environment. The sec-tions below discuss measures for promoting planning, monitoring and evaluation. 4.4. Planning Planning is supported in Co-Lab by outlining the steps learners should take dur- ing each phase of the inquiry process. This type of suppsort is particularly useful for learners with lower levels of self-regulation ( Vermunt, 1998 ), and research suggests that Co-Lab /C213s target audience matches this proﬁle. Manlove and Lazonder (2004) re- port that Co-Lab users between the ages of 15 and 17 hardly engaged in planningand frequently expressed their ignorance of the general approach to the learningtask. This observation prompted the development of a fully speciﬁed planning toolcalled the Process Coordinator (see Fig. 2 ). It contains a series of goals and subgoals that guide learners through the stages of
(see Fig. 2 ). It contains a series of goals and subgoals that guide learners through the stages of the inquiry process. Each goal statementcomes with a description stating what learners should do to accomplish that goal, and one or more hints that answer frequently asked questions. The purpose of this design is to promote self-regulation which in turn will yield higher knowledge gains.Attempts to validate this assumption are in progress. As learners /C213self-regulatory skills are expected to improve, planning support can be gradually faded. In keeping with the building metaphor, the Process Coordinatorcontains fewer and less explicit directions on higher ﬂoors. Fading may occurby removing the subgoals, the descriptions, and the hints in any preferred order.Finally, also the top level goals can be removed, leaving an open, unspeciﬁed plan- ning tool. The Process Coordinator thus provides a temporary support structure which can be considered another instance of model progression. 4.4.1. Monitoring In the monitoring phase, learners engage in control and observation of both their comprehension, attention, and performance in relation to the goals set during theanalysis phase. Monitoring can be triggered internally (e.g., learners spontaneouslyconsider their approach to the inquiry task) and externally (e.g., inconsistent resultsW.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 677
prompt learners to check the simulation /C213s settings). It is therefore somewhat diﬃcult to anticipate exactly when monitoring will (or should) occur. This in turn compli- cates the design of speciﬁc monitoring support – at least, without an intelligent tutor-ing system (cf. Veermans, 2002 ). Monitoring is supported by giving overviews of the learner /C213s actions in the envi- ronment ( De Jong & Van Joolingen, 1998 ). While Co-Lab does not provide ready- made overviews, it does facilitate learners in compiling overviews themselves. In theProcess Coordinator, learners can make notes associated to the goals present, andreview these on a History page. Learners also can tick oﬀ goals they consider completed. 4.4.2. Evaluation Evaluation pertains to a judgment of learning outcome as well as the learning process. While there often is no clear-cut distinction between evaluation and moni-toring, Scho¨n (1991) diﬀerentiates between reﬂection on action from reﬂection in ac- tion. Reﬂection in action pertains to monitoring activities, whereas reﬂection onaction can be likened to evaluation activities which occur at ‘‘certain stopping points’’ during an activity, often at the end of the learning process. Process displays and process prompts have been used to promote evaluation of learners engaged in discovery learning ( Lin, Hmelo, Kinzer, & Secules, 1999 ). A process display shows explicitly to learners what they are doing to solve a task. Inlearning environments this is often a trace or history of student actions. Processprompts give learners the opportunity ‘‘ ...to explain and evaluate what they do Fig. 2. Screenshot of the Process Coordinator.678 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
before during and after problem solving acts’’ ( Lin et al., 1999 ). These prompts are usually in the form of questions posed to the student by the learning environment.Lin and Lehman /C213s (1999) study of diﬀerent prompt types found that prompting learners to justify their reasoning directed learner /C213s attention more to understanding ‘‘when, why, and how to employ experiment design principles and strategies’’ (p. 837). This in turn enabled better transfer of their understanding to novel problems. Co-Lab utilizes both process displays and process prompts via the multiple views within the Process Coordinator. In the goal view, a process model is supplied to thelearners in the form of goals and subgoals which gives learners an overview of theprocess they should engage in. The process prompts are supplied in the form of hintsper sub-goal and take a question and answer format. The history view within theprocess coordinator shows all learner actions organized under the goals provided.Finally both the history and the goal views are combined within the report view. It enables learners to see their goal progress within the goal view, along with the notes and products they have made in the history view. The report view also providesa template structure where learners write a report of their ﬁndings. The templatespeciﬁes report sections along with descriptions which assist learners in writing outwhat they have learned from their inquiries and what they have learned about theprocess of inquiry. 5. Facilitating modeling Mental models are the internal representations we hold of our world. We use them to provide insight into how to reason over a particular problem, domain or sit-uation ( Jonassen, 1995 ). Assisting learners in acquiring appropriate mental models of physical systems is one of the main purposes of scientiﬁc discovery learning. Com-puter modeling has been recognized as an eﬀective method to facilitate mental modeldevelopment. By building an executable domain
as an eﬀective method to facilitate mental modeldevelopment. By building an executable domain model, learners externalize and test their conceptions of the variables in the simulation. The role of the model thus is to house domain knowledge and to be a vehicle for students /C213understanding and con- ceptual change ( Jonassen, Strobel, & Gottdenker, in press ). There are many types of modeling formalisms, from concept map notations to text based modeling found, for example, in goal tree structures (e.g., Lo¨hner, Van Joolingen, & Savelsbergh, 2003 ). When reasoning about the continuous physical sys- tems found in water management and green house gasses however, systems dynamicsmodeling appears to be the most appropriate to represent these systems ( Frederiksen & White, 1998; Jackson, Stratford, Krajcik, & Soloway, 1996 ). Such models reﬂect the dynamic nature of physical systems, by allowing simulation, envisioning the con-sequences of all direct and indirect relationships between variables in a time-depend-ent system. The use of generic variable types such as stocks, constants and auxiliariesprovide learners with ‘‘mini’’ mental models of how to think about variables andtheir relationships in the system. The Co-Lab environment contains a Model Editortool which allows learners to construct systems dynamic models of the phenomenadisplayed in the simulation.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 679
When learners construct a model, they tend to go through four stages: (1) model sketching, (2) model speciﬁcation, (3) data interpretation, and (4) model revision(cf.Hogan & Thomas, 2001 ). As Co-Lab perceives modeling as an integral part of scientiﬁc inquiry, the stages in the modeling process are closely related to thephases of the inquiry learning process identiﬁed by Njoo and De Jong (1993) .I n the orientation phase, learners sketch a model outline to express their initial under- standing of the phenomena from the simulation. In the hypothesis phase, this sketchis transformed into a runnable model by specifying the relations between the varia-bles in the model. During data interpretation, learners compare their model to datafrom the simulation which, during the conclusion phase, feeds their decision to revisethe model. Given the intertwined nature of inquiry and modeling, much of the support which has been explained in the previous sections also applies to supporting modeling activities. The sections below therefore present the support learners can use for model building per se. 5.1. Support for model sketching During problem analysis, learners can make a situation drawing to express their initial mental model and understanding of a domain ( Forbus, Carney, Harris, & Sherin, 2001; Oliver & Hannaﬁn, 2001 ). The sketch often serves to scaﬀold the com- plexities found in simulation-based inquiry learning, where learners have to unravel various, simultaneously interacting cause/eﬀect relationships ( Jackson et al., 1996 ). Co-Lab supports model sketching through a graphical modeling tool which allowslearners to build an icon-based model structure (see Fig. 3 ). Additionally, learners are supported within Co-Lab in learning systems dynamic modeling via a tutorialand model editor help ﬁles. 5.1.1. Support for model speciﬁcation In model speciﬁcation, learners deﬁne the relations between variables in their model. These relations initially represent a learner /C213s
relations between variables in their model. These relations initially represent a learner /C213s assumptions of how variables interact; later the relations represent the learner /C213s insights derived from the simu- lation. According to Lo¨hner et al. (2003) , qualitative speciﬁcations are appropriate during the initial stages of the modeling process when learners still lack a clearunderstanding of the model they are building. In fact scientists in practice oftenstart with a qualitatively expressed model ( White & Frederiksen, 1990 ). By qual- itatively expressing relationships, learners begin to construct a bridge between their initial mental model of the system (as found in the model sketch) and the target model ( Jackson et al., 1996 ). Quantitative, formula-based speciﬁcations are more useful for the later part of the modeling process, when the model is ﬁnalized.As both forms of representation play a distinct role in the modeling process, learn-ers are best supported by a modeling tool that accommodates a mixedrepresentation. Co-Lab /C213s Model Editor was designed according to these guidelines. It allows learners to specify their model by selecting pre-deﬁned qualitative relations, drawing680 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
graphs, or entering mathematical formulas (see Fig. 4 ). As variable and property identiﬁcation progresses across a qualitative to quantitative spectrum ( Njoo & De Jong, 1993 ), learners are prompted to specify their model accordingly, using qualita- tive relations to specify their hypotheses and quantitative relations to express insightsderived from the simulation. 5.2. Support for data interpretation and model revision Running a model to generate data is the primary means of model testing and revising ( Forbus et al., 2001; Frederiksen & White, 1998 ). The data resulting from model runs need to be interpreted by the learner to establish how well the data fromtheir model match with the results from the simulation. This intrinsic feedback amodel can give is an important factor also in assisting students in evaluating their domain understanding ( Jackson et al., 1996 ). To facilitate the comparison of data between simulation runs and model runs, Co- Lab facilitates the display of the output of the experiments with the simulation orremote lab and the learner-constructed model in a single graph (see Fig. 1 ). Addi- tionally a curve ﬁtting tool can help the learners in constructing a model by perform-ing a statistical analysis on the data collected. When learners select this option, thesystem calculates the goodness of ﬁt between the model output (as shown in thegraph) and a given theoretical distribution (e.g., a curvilinear relationship). Examining and interpreting model output is essential for understanding scientiﬁc phenomena. Yet research shows that students use model output sparingly, usually onlyat the end of a modeling session to check if obtained results match their initial expecta-tions ( Hogan & Thomas, 2001; Stratford, Krajcik, & Soloway, 1997 ). Modeling should Fig. 3. Screenshot of the Model Editor.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 681
involve dynamic iterations between examining output and revising models. As learners generally fail to spontaneously adopt such an iterative approach, the learning environ-ment should prompt them to do so. In Co-Lab, these prompts are oﬀered in the ProcessCoordinator, fully integrated with the directions for systematic experimentation. 6. Facilitating collaboration In order for students to ‘‘act like scientists’’, a discovery learning environment should support working in collaborative groups. An additional advantage of collab-oration is that it promotes higher achievement than individual learning strategies(e.g., Lou et al., 1996 ). Other studies have shown that this eﬀect transfers to discov- ery learning. Paired students generally are more successful in discovering scientiﬁcmechanisms than single students (e.g., Okada & Simon, 1997; Teasley, 1995 ). These studies further demonstrate that the superiority of student pairs is attributable topeer interaction. Collaboration increases the likelihood that learners engage in the type of talk that supports learning, such as asking and answering of questions, rea- soning and conﬂict resolution. Collaboration also promotes regulation of the learning task. In a study by Laz- onder (submitted) , pairs of students showed relatively higher proportions of self- regulatory activities than single students. More speciﬁcally, dyads exhibited a richerrepertoire of strategies to solve problems. They were also more proﬁcient in monitor-ing each other /C213s actions which facilitated early detection and correction of errors. The results for evaluation also diﬀered in favor of the dyads. They crosschecked ini- tial answers more frequently and modiﬁed initially incorrect responses more than twice as often. Further research is needed to determine if these eﬀects generalize todiscovery learning. These studies however, focused on face-to-face collaboration. Comparisons of computer-mediated and face-to-face collaboration suggest that
collaboration. Comparisons of computer-mediated and face-to-face collaboration suggest that computer-mediatedcollaboration is characterized by a number of deﬁciencies. A number of studies have,for instance, found that face-to-face dyads attain higher performance scores than Fig. 4. Qualitative, graphical, and quantitative speciﬁcation of relations in a model.682 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
students who collaborate online (e.g., Salminen, Marttunen, & Laurinen, 2003; Van der Meijden & Veenman, in press ). Face-to-face dyads also have more prolonged dis- cussions on the learning task; communication in the computer-mediated dyads ismore directed at coordinating eﬀorts, operating the communication tool, andexpressing emotions. Together, these ﬁndings indicate that computer-mediated collaboration can pro- mote scientiﬁc discovery learning, but that collaboration itself should be promotedfor learners to take full advantage of each others presence. This implication is relevantto Co-Lab, as this environment is designed for synchronous online collaboration, per-mitting learners to work together in real time while being geographically dispersed. Co-Lab allows for this type of collaboration by providing several means of sup- port for collaboration. The Co-Lab environment is a shared space, in which learnerscan see each others actions and to which each learner can contribute. Also Co-Lab includes a communication channel based on chat, as well as a place for storing com- monly built objects as well as and functions that increase social presence. Thesekinds of support for collaboration are elaborated below. Although such supportive features are available (e.g., reﬂective notebooks, collab- orative concept maps, communication widgets), their eﬃcacy in synchronous onlinecollaboration has not yet been assessed. Yet empirical validation is needed becauseCo-Lab /C213s target audience is familiar with online communication technologies. To illustrate, Lazonder, Wilhelm, and Ootes (2003) examined the eﬃcacy of sentence openers to foster peer interaction. Sentence openers are pre-deﬁned opening phrases students can readily select from a menu in their chat tool. The students in this studyhardly used sentence openers, a result that was attributable to their chat experience.Students were accustomed to typing chat messages and maintained in this chat style,being unwilling or
were accustomed to typing chat messages and maintained in this chat style,being unwilling or unable to adopt an alternative way to create messages. This lead tothe decision that sentence openers should not be included in Co-Lab. 6.1. Support for student interaction Peer-to-peer collaboration encourages students to articulate their thoughts, which in turn has a facilitative eﬀect on achievement and regulation. Co-Lab enables socialinteraction through a chat tool. Consistent with the building metaphor, the chat isroom-speciﬁc, which means that by default messages can only be read in the roomin which they were sent. Usability tests revealed that this division was too strict as it impeded the learning dis- course. Learners speciﬁcally asked for an ‘‘intercom’’ to contact group members in dif- ferent rooms. This functionality was implemented in the form of the ‘‘Send to ﬂoor’’ button. By pressing this button, the unsent chat message becomes visible in every room. 6.2. Support for shared knowledge building Constructing shared knowledge is the ultimate goal of collaborative learning. This goal has two important consequences for the tools in collaborative discovery learn-ing environments. One is that shared knowledge must be represented explicitly soW.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 683
learners can see the objects they are working on and talking about. Learners should thus be oﬀered a joint space to post their ideas, hypotheses, models and so on. Thesecond implication is that the learners /C213multiple perspectives should be integrated. This means that the tools should allow learners to manipulate the objects representedin the joint space. The notion of shared workspaces was central to the design of Co-Lab. In a way, Co- Lab itself is one shared workspace: the environment holds no private tools or spaces, soeverything a learner does is readily visible to and editable by his/her group members. Toensure that the collaboration proceeds in an orderly way, Co-Lab introduces the notionofcontrol . In each room only one learner (the ‘‘leader’’) can perform all actions; the others are merely allowed to do reversible actions that have no permanent trace inthe learning environment. What is considered to be reversible action can be controlledon a tool-by-tool and even a button-by-button basis. An example of a reversible action is choosing a plot of a speciﬁc variable out of an existing data set, i.e. opening a speciﬁc view on existing data. An irreversible action would be creating a new data set, or mak-ing changes to a model. Learners can request and pass on control to each other bymeans of a dedicated control tool, which uses a traﬃc light metaphor. 6.3. Support for social presence Face-to-face collaboration is dominated by social presence (a sense of being to- gether) where individuals can interact eﬀortlessly. As online collaboration is weak in social presence, designated tools are needed to increase learner /C213s sense of being together (Kirschner, 2002 ). Co-Lab /C213s Locator tool allows learners to check which group mem- bers are online and which room they are in. Manlove and Lazonder (2004) showed that learners use this tool frequently to see if group members have entered the environmentor joined them when changing rooms. The Locator also served to
members have entered the environmentor joined them when changing rooms. The Locator also served to trace group memberswho did not contribute to the ongoing chat discussion. 7. Co-Lab evaluation studies Apart from initial speciﬁcation studies and usability studies mentioned above, that lead to modiﬁcations of Co-Lab design, Co-Lab has been evaluated with learn-ers in two formative and two summative evaluation studies. The results of the form-ative evaluation studies also contributed to the ﬁnal product. The current section willbrieﬂy describe these studies. Full reports are available in Lazonder (2004) . As Co- Lab is a large comprehensive system, evaluation studies have had to focus on speciﬁc aspects of it, rather than evaluating the whole system. The ﬁrst formative evaluation study focused on learners /C213general impressions of the system. The goal was to evaluate whether students are able to use the Co-Labenvironment in its natural state. To this end learners ( N= 43) went through a full Co-Lab session, although the model in this session was relatively simple. Learners /C213 actions were logged and they ﬁlled in a questionnaire after completing the session.This lead to a number of remarks regarding the room metaphor and workﬂow within684 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
the environment: in a complex environment like Co-Lab students indicate a high need for transparency (knowing what is the current task, knowing where co-workersare, knowing where information can be found) as well as a need to improve themeans for collaborative tasks, such as planning and encouraging. This lead tochanges in communication (chat across rooms) and to the availability of the process coordinator in every room. The second formative evaluation study examined eﬃciency in terms of how stu- dents work with Co-Lab with minimal guidance from evaluators or the environment.The goal was to (1) describe working patterns and group approaches to the learningtask and to obtain base-line data which shows how students are or are not regulatingtheir inquiry. Students ( N= 39) worked in a minimally guided Co-Lab environment on a simple inquiry task. It was found that in the early stages of the session, the labwork prevailed; learners showed a preference for the lab room, only later on mode- ling and more systematic experimentation were taken on by the learners. With respect to regulation it was found that most regulation eﬀort went toward regulatingthe collaborative process, rather than the learning task. Again this supports the sug-gestion to integrate tools designed to promote learners /C213regulation into rooms where the inquiry task is being performed. In the ﬁrst summative evaluation study, the collaboration as envisioned by Co- Lab was compared to a face-to-face collaboration setting. The purpose was to inves-tigate in what way the on-line communication mode in Co-Lab would inﬂuence the task attainment in Co-Lab, compared to the more traditional face-to-face mode. Stu- dents ( N= 40) worked on two Co-Lab ﬂoors, where the ﬁrst served an introductory purpose. The analysis focused mainly on the modeling task. It was found that therewas no signiﬁcant diﬀerence in product of learning (the quality of the created mod-els), but there were diﬀerences in process. Face-to-face
learning (the quality of the created mod-els), but there were diﬀerences in process. Face-to-face working students showedmore superﬁcial behavior and actions of specifying model values had a negative ef-fect on learning product, which was not the case for the on-line collaborating dyads.This indicates that the two collaborative modes are essentially diﬀerent, and that the on-line collaborative mode employed by Co-Lab can promote deeper processing. Finally, the second summative study speciﬁcally evaluated the process coordina- tor that is present in Co-Lab. The study compared two groups of students ( N= 61), one working with a pre-ﬁlled process coordinator, and one for which this tool wasleft empty, and for which students had to ﬁll it themselves. The group with the ﬁlledprocess coordinator performed more planning actions and used the process coordi-nator more often than the other group. This study supports research indicating thestudents need scaﬀolds such as the process coordinator in order to fully beneﬁt from the complexity and richness of the data provided for them, when working in environ- ments like Co-Lab. 8. Conclusion In this contribution, the Co-Lab learning environment served as a vehicle to express the authors /C213views on collaborative discovery learning. Co-Lab /C213s initialW.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 685
design was based on insights gleaned from instructional theory and empirical re- search. Usability tests were conducted to improve the user-friendliness of the envi-ronment and the intuitiveness of its tools. Formative and summative evaluationswere also performed to assess Co-Labs potential to foster collaborative inquirylearning. As an environment, Co-Lab is suitable to provide a means for an integrated ap- proach for collaboration, modeling and inquiry. Co-Lab is the ﬁrst environment inwhich these three learning modes are brought together and integrated. Co-Lab /C213s structure keeps the complexity of the environment within reasonable limits, asmay be inferred from the unguided activities that learners have undertaken. Alsospeciﬁc instructional support, such as the process coordinator, qualitative modelingand the oﬀering of challenging assignments provides a means for engaging studentsin an authentic inquiry context. The studies performed with Co-Lab indicate that the way of oﬀering support is well on track, however more research is needed to understand Co-Lab and to make surethat Co-Lab will eventually be used in classrooms. Research is needed and plannedinto the assessment of learning in collaborative inquiry environments: how can we as-sess learning products such as inquiry skills, deeper domain knowledge and skills forcollaboration. Although attempts have been made to measure knowledge from dis-covery learning ( Swaak & De Jong, 1996 ) more research is needed to cover the full range of knowledge types that express a learner /C213s proﬁciency in inquiry and modeling. In order to bring Co-Lab to actual education more research and development is also needed. As such Co-Lab represents a developmental end point towards collab-orative inquiry, but a path leading to this end point has not yet been laid out. Teach-ers will not accept the use of an integrated system like Co-Lab immediately, thus animplementation trajectory needs to be carefully designed. A follow-up
Co-Lab immediately, thus animplementation trajectory needs to be carefully designed. A follow-up project, calledReCoIL (Resoirces for Collaborative Inquiry Learning) is currently underway inproviding such an implementation strategy. Acknowledgements The work reported here was supported by the European Community under the Information Society Technology (IST) School of Tomorrow programme (contractIST-2000-25035). The authors are solely responsible for the content of this article.It does not represent the opinion of the European Community, and the EuropeanCommunity is not responsible for any use that might be made of data appearing therein. Partners in the Co-Lab project are: the University of Twente, the Univer- sity of Amsterdam, The University of Murcia, Studio TEOS, the Leibnitz Institutfur Pa ¨dagogische Naturwissenschaften. The authors thank the following persons who contributed to the Co-Lab system and project: Anjo Anjewierden, Jasper Be-deaux, Martin Beugel, Thorsten Bell, Davide Biolghini, Ulrich Bosler, Ben Bruid-egom, Alberto Ceccarelli, Miguel Celdran, Marijn van Eupen, Leendert vanGastel, Jose van Gelderen, Stefano Gobbi, Simone Lo ¨hner, Ernesto Martin, Ton ˜i Martı ´nez Carreras, Eduardo Martinez Gracia, Laura Miani, Tina Miggiano, Man-686 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
uel Mora, Maarten Pieters, Sascha Schanze, Jakob Sikken, Patrick Sins, Antonio Gomez Skarmeta, Roberto de Souza, Peter Uylings, Pascal Wilhelm, ThiloWu¨nschler. References Brown, J. S., Collins, A., & Duguid, P. (1989). Situated cognition and the culture of learning. Educational Researcher, 18 (1), 32–42. Bruner, J. (1961). The act of discovery. Harvard Educational Review, 31 , 21–32. De Jong, T., & Van Joolingen, W. R. (1998). Scientiﬁc discovery learning with computer simulations of conceptual domains. Review of Educational Research, 68 , 179–202. Dunbar, K. (2001). What scientiﬁc thinking reveals about the nature of cognition. In K. Cowley, C. D. Schum, & T. Okada (Eds.), Designing for science: Implications from everyday, classroom and professional settings (pp. 47–72). Mahwah: Erlbaum. Elshout, J. J. (1987). Problem solving and education. In E. de Corte, H. Lodewijks, R. Parmentier, & P. Span (Eds.), Learning and instruction (pp. 259–273). Oxford: Pergamon. Forbus, K., Carney, K., Harris, R. & Sherin, B. (2001). A qualitative modeling environment for middle- school students: a progress report. In Proceedings of the 15th international workshop on qualitative reasoning (QR01) . Available: http://qrg.northwestern.edu/papers/papers.htm . Frederiksen, J. R., & White, B. Y. (1998). Teaching and learning generic modeling and reasoning skills. Interactive Learning Environments, 5 , 33–51. Gijlers, H., & De Jong, T. (2004). Het ondersteunen van samenwerkend ontdekkende leren in een simulatie omgeving [Supporting collaborative discovery learning in a simulation environment] . Paper presented at the Onderwijs Research Dagen 2004, Utrecht, The Netherlands. Available: http://edu.fss.uu.nl/ord/ . Hogan, K., & Thomas, D. (2001). Cognitive comparisons of students /C213systems modeling in ecology. Journal of Science Education and Technology, 10 , 75–96. Jackson, S., Stratford, S. J., Krajcik, J. S., & Soloway, E. (1996). Making systems dynamics modeling accessible to pre-college
Krajcik, J. S., & Soloway, E. (1996). Making systems dynamics modeling accessible to pre-college science students. Interactive Learning Environments, 4 , 233–257. Jonassen, D. H. (1995). Operationalizing mental models: strategies for assessing mental models to support meaningful learning and design-supportive learning environments. In J. L. Schnase & E. L. Cunnius(Eds.), Proceedings of Cscl /C21395: The ﬁrst international conference on computer support for collaborative learning: October 17–20, 1995 . Bloomington, Indiana, USA: Indiana University. Available: http:// www.ittheory.com/jonassen2.htm . Jonassen, D. H., Strobel, J. & Gottdenker, J. (in press). Modeling for meaningful learning. In R. Floden, K. McKevitt (Eds.), Technology for meaningful learning . New York: Teacher /C213s College Press. Kirschner, P. A. (2002). Can we support CSCL? Educational, social and technological aﬀordances for learning . Inaugural address, Heerlen, The Netherlands: Open Universiteit Nederland. Kluwe, R. H. (1982). Cognitive knowledge and executive control: Metacognition. In D. R. Griﬀen (Ed.), Animal mind–human mind (pp. 201–224). New York: Springer-Verlag. Lazonder, A. W. (submitted). Do two heads search better than one? Eﬀects of student collaboration on Web search behavior and search outcomes . Lazonder, A. W. (Ed.) (2004). Report on evaluation studies, collaborative laboratories for Europe . Deliverable D8, project report. Enschede, The Netherlands: University of Twente. Lazonder, A. W., Wilhelm, P., & Ootes, S. A. W. (2003). Using sentence openers to foster student interaction in computer-mediated learning environments. Computers and Education, 41 , 291–308. Lin, X., Hmelo, C., Kinzer, C. K., & Secules, T. J. (1999). Designing technology to support reﬂection. Educational Technology Research and Development, 47 (3), 43–62. Lin, X., & Lehman, J. D. (1999). Supporting learning of variable control in a computer based biology environment: eﬀects of prompting college students to
variable control in a computer based biology environment: eﬀects of prompting college students to reﬂect on their own thinking. Journal of Research in Science Teaching, 36 , 837–858. Lo¨hner, S., Van Joolingen, W. R., & Savelsbergh, E. R. (2003). The eﬀect of external representation on constructing computer models of complex phenomena. Instructional Science, 31 , 395–418.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 687
Lou, Y., Abrami, P. C., Spence, J. C., Poulson, C., Chambers, B., & /C212d Apollonia, S. (1996). Within-class grouping: a meta-analysis. Review of Educational Research, 66 , 423–458. Manlove, S. A. & Lazonder, A. W. (2004). Self-regulation and collaboration in a discovery learning environment . Paper presented at the ﬁrst EARLI Metacognition SIG conference, Amsterdam. Available: http://users.edte.utwente.nl/lazonder/homepage/NL/Publijst.html . Njoo, M., & De Jong, T. (1993). Supporting exploratory learning by oﬀering structured overviews of hypotheses. In D. Towne, T. de Jong, & H. Spada (Eds.), Simulation-based experiential learning (pp. 207–225). Berlin: Springer-Verlag. Okada, T., & Simon, H. A. (1997). Collaborative discovery in a scientiﬁc domain. Cognitive Science, 21 , 109–146. Oliver, K., & Hannaﬁn, M. (2001). Developing and reﬁning mental models in open-ended learning environments: a case study. Educational Technology Research and Development, 49 , 5–32. Penner, D. E. (2001). Cognition, computers, and synthetic science: Building knowledge and meaning through modeliling. Review of Research in Education, 25 , 1–37. Salminen, T., Marttunen, M. & Laurinen, L. (2003). The quality of secondary school students /C213 argumentative dialogue: comparing face-to-face and chat debates . Paper presented at the 10th EARLI Conference, August 26–30, Padova, Italy. Schauble, L., Klopfer, L., & Raghavan, K. (1991). Students /C213transitions from an engineering to a science model of experimentation. Journal of Research in Science Teaching, 28 , 859–882. Scho¨n, D. (1991). The reﬂective practitioner: How professionals think in action . Hants: Ashgate. Stratford, S. J., Krajcik, J. & Soloway, E. (1997, March). Secondary students /C213dynamic modeling processes: Analyzing, reasoning about, synthesizing, and testing models of stream ecosystems . Paper presented at the annual meeting of the American Educational Research Association, Chicago, IL. Swaak, J., & de Jong, T. de (1996).
of the American Educational Research Association, Chicago, IL. Swaak, J., & de Jong, T. de (1996). Measuring intuitive knowledge in science: the what-if test. Studies in Educational Evaluation, 22 , 341–362. Teasley, S. D. (1995). The role of talk in children /C213s peer collaborations. Developmental Psychology, 31 , 207–220. Van der Meijden, H. & Veenman, S. (2004). Face-to-face versus computer-mediated communication in a primary school setting. Computers in Human Behavior . doi: 10.1016/j.chb.2004.10.005 . Van Joolingen, W. R., & De Jong, T. (1993). Exploring a domain through a computer simulation: traversing variable and relation space with the help of a hypothesis scratchpad. In D. Towne, T. deJong, & H. Spada (Eds.), Simulation-based experiential learning (pp. 191–206). Berlin: Springer-Verlag. Van Joolingen, W. R., & De Jong, T. (2003). SimQuest, authoring educational simulations. In T. Murray, S. Blessing, & S. Ainsworth (Eds.), Authoring tools for advanced technology learning environments: Toward cost-eﬀective adaptive, interactive, and intelligent educational software (pp. 1–31). Dordrecht: Kluwer. Veermans, K. (2002). Intelligent support for discovery learning . Unpublished doctoral dissertation, Enschede, University of Twente, The Netherlands. Vermunt, J. (1998). The regulation of constructive learning processes. British Journal of Educational Psychology, 68 , 149–171. White, B., & Frederiksen, J. R. (1990). Causal model progressions as a foundation for intelligent learning environments. Artiﬁcial Intelligence, 42 , 99–157.688 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
Co-Lab: research and development of an online learning environment for collaborative scientiﬁc discovery learning Wouter R. van Joolingena,b,*, Ton de Jongb, Ard W. Lazonderb, Elwin R. Savelsbergha, Sarah Manloveb aGraduate School of Teaching and Learning, University of Amsterdam, Wibautstraat 2-4, 1091 GM Amsterdam, The Netherlands bDepartment of Instructional Technology, University of Twente, The Netherlands Available online 8 December 2004 Abstract There are many design challenges that must be addressed in the development of collabora- tive scientiﬁc discovery learning environments. This contribution presents an overview of howthese challenges were addressed within Co-Lab, a collaborative learning environment in whichgroups of learners can experiment through simulations and remote laboratories, and express acquired understanding in a runnable computer model. Co-Lab /C213s architecture is introduced and explicated from the perspective of addressing typical problem areas for students withincollaborative discovery learning. From this view the processes of collaboration, inquiry, and modeling are presented with a description of how they have been supported in the past and how they are supported within Co-Lab /C213s design and tools. Finally, a research agenda is proposed for collaborative discovery learning with the Co-Lab environment. /C2112004 Elsevier Ltd. All rights reserved. Keywords: Collaborative learning; Inquiry learning; Learning environments; Dynamic modeling 0747-5632/$ - see front matter /C2112004 Elsevier Ltd. All rights reserved. doi:10.1016/j.chb.2004.10.039*Corresponding author. E-mail address: w.r.vanjoolingen@uva.nl (W.R. van Joolingen).Computers in Human Behavior 21 (2005) 671–688 www.elsevier.com/locate/comphumbehComputers in Human Behavior
1. Introduction Socio-constructivist learning theories perceive learning as a constructive, situated and collaborative process. These theories converge on the notion that learners developunderstanding of a domain by working on authentic tasks in realistic settings. Task performance preferably occurs in collaboration with peers, and should be regulated by the learners (instead of the teacher or the learning material). In science education, these notions of learning can be implemented by letting learners ‘‘act like scientists’’. That is, learners should perform experiments to dis-cover relationships between phenomena, and construct models to express theirunderstanding. Clearly, these learning activities are more constructive by naturethan, for instance, listening to lectures or solving paper-and-pencil physics problems.Experimentation and modeling are also authentic activities that reﬂect the way sci- entists go about in studying unknown phenomena. Learners thus develop domain knowledge and, at the same time, familiarize themselves with a scientist /C213s way of working and thinking (cf. Brown, Collins, & Duguid, 1989 ). Such enculturation can be further enhanced through collaboration. Teamwork has long since been acommon practice in science and many scientiﬁc discoveries were a joint eﬀort ( Dun- bar, 2001 ). Organizing science education around collaborative inquiry and modeling activi- ties requires innovative, student-centered forms of instructional support. Collabora- tive discovery learning environments are a potentially powerful means to oﬀer this type of support, provided that their design meets certain criteria. One obvious de-mand concerns the presence of tools learners can use to explore a task domainthrough experimentation. Yet merely doing experiments does not capture the fullrange of scientists /C213activities, nor will it develop deeply rooted, transferable knowl- edge and skills. Structural changes in domain knowledge require reﬂection in con-junction
knowl- edge and skills. Structural changes in domain knowledge require reﬂection in con-junction with modeling, and reﬂection is a natural component of the socialinteraction that occurs in collaboration ( Penner, 2001 ). Collaborative discovery learning environments should therefore comprise tools that support inquiry through experimentation, domain modeling and student collaboration. This article exempliﬁes how this type of support might be brought about. It does so by articulating the design considerations for Co-Lab, a learning environment inwhich groups of learners can experiment through simulations and remote laborato-ries, and express acquired understanding in a runnable computer model. The nextsection presents an overview of Co-Lab /C213s basic architecture. The sections that follow elucidate how the processes of inquiry, modeling and collaboration are supported within the environment and its tools. In the ﬁnal section, a research agenda is pro- posed for collaborative discovery learning with the Co-Lab learning environment. 2. The structure of Co-Lab learning environments Co-Lab supports collaborative discovery learning in the natural sciences at the upper secondary level and the ﬁrst years in university. Content is currently available672 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
for four domains: water management, greenhouse eﬀect, mechanics and electricity. Water management and greenhouse eﬀect are extensive courses that cover the rich-ness of these interdisciplinary domains. Both courses comprise several modules ofdiﬀerent levels of complexity. A building metaphor was used to elucidate this multi-level structure. Learners have access to one or more buildings symbolizing the courses in the various domains. Each building contains multiple ﬂoors (representing the modules) and each ﬂoor hasmultiple rooms to structure the learners /C213activities. Experimenting and modeling are supported in the Lab and Theory room, respectively. The Meeting room is intendedfor planning and monitoring; the Hall is where learners gather and collect theirassignment. Buildings and ﬂoors thus organize the domain, rooms organize thelearning activities. Fig. 1 shows the Co-Lab interface that appears upon entering a ﬂoor. The top- right part of the screen is the main working area. Here students can select various tools for experimentation and modeling. In keeping with the building metaphor, dif-ferent tools are available in diﬀerent rooms, so the content of this part of the screendepends on the learner /C213s current location. The left-hand side of the screen houses generic tools for navigation and collabo- ration as well as a tool to move learning objects across rooms. This part of the screenremains unchanged when students switch rooms, making its tools available in allrooms. The same is true for the bottom part of the screen where a synchronized chat tool supports communication. Fig. 1. Annotated screenshot of Co-Lab /C213s interface.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 673
3. Co-Lab /C213s collaborative discovery learning orientation In collaborative discovery learning, groups of students examine scientiﬁc phenom- ena and express their shared understanding in a runnable computer model. Learnersthus engage in three analytically distinct processes, namely inquiry, modeling and collaboration. However, in Co-Lab the demarcation between these processes is less clear cut. Collaboration, for instance, runs as a continuous thread through the dis-covery learning process, aﬀecting the way in which inquiry and modeling processesare performed and should be supported. Furthermore, modeling is integral to theinquiry process. Learners express their initial understanding of scientiﬁc phenomenain a model sketch, which is then used to predict and explain what will occur in thephenomena being modeled. By testing these hypotheses with the simulation or theremote lab, learners gain knowledge they can use to reﬁne or extend their model. The sections below detail Co-Lab /C213s orientation to collaborative discovery learn- ing. The processes of inquiry, modeling, and collaboration are described in separatesections, despite the dynamic interplay between them. 4. Facilitating inquiry learning Inquiry learning pertains to the acquisition of knowledge by a learner-regulated process of data collection and data interpretation. The inferential processes that build upon the data gathered by the learner should lead to the discovery of rules thatgovern the relations between variables in a given domain. This means that inquirylearning has shifted from the discovery of concepts (as it was originally conceivedin Gestalt psychology and the work of Bruner (1961) ) to discovery of rules ( De Jong & Van Joolingen, 1998 ). In Co-Lab, learners can collect data from built-in simulations, remote laboratories and remote databases. Regardless of the type of data source, learners are to unravel the relations between input and output variables through systematic experimentation.
are to unravel the relations between input and output variables through systematic experimentation. This process proceeds through ﬁve phases: analysis, hypothesis generation, experimentdesign, data interpretation, and conclusion. Njoo and De Jong (1993) coined the term transformative processes to indicate that the learners /C213activities in these phases are per- formed for the sole purpose of yielding knowledge. Regulatory processes , in contrast, serve to manage and control the inquiry learning process. Planning, monitoring andevaluation are typical instances of regulatory processes. A review by De Jong and Van Joolingen (1998) has produced a comprehensive overview of the diﬃculties learners encounter in inquiry learning. How these prob- lems were addressed in Co-Lab is discussed in the sections below. 4.1. Support for transformative processes4.1.1. Hypothesis generation One of the most pertinent problems in inquiry learning is formulating syntacti- cally correct (i.e., testable) hypotheses. One solution is to provide learners with674 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
partly speciﬁed hypotheses. Van Joolingen and De Jong (1993) introduced a hypoth- esis scratchpad which contained templates to formulate syntactically correct predic-tions. Learners could select a statement from a pull-down menu and complete it byadding variables, relations and condition. Unfortunately, usability problems pre-vented learners from taking full advantage of this tool. Bearing these problems in mind, Gijlers and De Jong (2004) converted the ideas of the hypotheses scratchpad into a proposition table. This tool comprised a list of fullyspeciﬁed hypotheses, the students /C213beliefs about a hypothesis and their willingness to test it (the proposition table was used in a collaborative setting). Students using theproposition table outperformed both the hypotheses scratchpad and the controlgroup on a test measuring intuitive knowledge. Protocol analysis revealed that thesediﬀerences arose because students in the proposition table group produced morestatements about hypothesis generation and discussed a larger number of hypotheses. Despite these favorable results, oﬀering fully speciﬁed hypotheses has the poten- tial disadvantage of revealing the key variables and relations to the learner. Thismight cause learners to skip the analysis phase and start experimenting on the basisof patchy knowledge. Co-Lab supports hypothesis construction in a graphical in-stead of a verbal way, using the built-in modeling tool in order to restrain learnersfrom jumping the gun. Learners use their model to express their propositions abouta relation between two variables. During the initial stages, pre-speciﬁed, qualitative relations can be selected from a drop-down menu. Hypotheses can be tested by com- paring the outcomes of the model with the simulation /C213s output. During the later stages, qualitative relations can gradually be replaced by quantitative ones, usingscientiﬁc formulas. 4.1.2. Experiment design Another class of problems pertains to the design of experiments.
formulas. 4.1.2. Experiment design Another class of problems pertains to the design of experiments. These include the design of inconclusive experiments, ineﬃcient experimentation behavior, and the de- sign of experiments that are not intended to test a hypothesis. Inconclusive experiments often arise because learners vary too many variables at once. Experimentation hints such as ‘‘vary only one variable at a time’’ can improvelearners /C213experimentation behavior in this respect ( De Jong & Van Joolingen, 1998 ). In Co-Lab, such hints are oﬀered in the Process Coordinator and in help ﬁles. Ineﬃcient experimentation occurs when learners fail to design informative experiments or when they repeat previous experiments. The former may be diﬃ-cult to overcome because inquiry learning essentially is a learner-directed process. Repetitions on the other hand might be avoided by providing insight into the experiments a learner has already performed. To this end, SimQuest ( Van Joolin- gen & De Jong, 2003 ) simulations contain a monitoring tool that shows the initial values of input variables and end values of output variables for each experiment(Veermans, 2002 ). Learners can reveal the progress of output variables across time by selecting a given experiment from the tool and clicking the /C212replay /C213but- ton. The simulation is then run using the exact same settings as in the originalexperiment.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 675
Experimentation support in Co-Lab is more output-oriented in that learners can save experimental results instead of experimental settings. Learners can save tablesand graphs in the Object Repository and annotate these to identify the settings usedin the experiment. Tables and graphs can be retrieved by clicking the /C212restore /C213button (seeFig. 1 ). Designing experiments that are not intended to test hypotheses can be indicative of an engineering approach .Schauble, Klopfer, and Raghavan (1991) characterize this approach as one in which learners attempt to create a desirable outcome in-stead of trying to understand the model. Co-Lab seeks to resolve this problemby requiring learners to produce a comprehensive model. Assignments in Co-Labare therefore open-ended, merely instructing learners to come to grips with a phe-nomenon and model it. However, research suggests that additional experimenta-tion hints are needed. An exploratory study with Co-Lab revealed that experimentation in absence of any further support to the contrary shows learners engaging in an engineering approach ( Manlove & Lazonder, 2004 ). Learners merely used the water tank simulation (displayed in Fig. 1 ) to reach equilibrium through trial-and-error. Once they succeeded, they did not try to discover the sim-ulation /C213s underlying model by reaching equilibrium using diﬀerent settings (as suggested in the text of the assignment). 4.2. Data interpretation Learners often experience diﬃculties in drawing conclusions from their data. Visual- izing data is a well-tried solution. A linear relationship between two variables can, forinstance, more easily be identiﬁed from a graph than from numerical values in a table.Nevertheless the construction and interpretation of graphs appears to be both time con-suming and error prone. Co-Lab /C213s graph tool therefore automatically generates a graph whenthesimulationisrun.Learnerscanthusreadilyinterprettheresultswithouthavingto convert raw data into a graph.
convert raw data into a graph. Co-Lab does support across-experiment comparison of data by allowing the learner to compare the plots of the results of more than one experiment in onegraph. An interesting extension could be to add the extended version of Veer- mans /C213(2002) monitoring tool to the Co-Lab environment which allows learners to arrange stored experiments according to one of the variables to compare var-ious experiments. Between experiment comparison is further supported by agraphing option that allows learners to plot the end value of an output variableobtained in a series of experiments in a single graph. This option supports learn- ers in performing a meta-analysis of their own data to extrapolate relations between variables. 4.3. Support for regulatory processes Regulatory processes are pivotal to successful inquiry learning. While constructiv- ists advocate that learners should independently engage regulatory activities such asplanning, monitoring and evaluation, research has consistently shown that addi-676 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
tional support is needed for learners to become ‘‘active agents of their own inquiry learning’’ ( Kluwe, 1982 ). Task complexity can get in the way of learners /C213spontaneous use of self-regulatory skills ( Elshout, 1987 ). This problem might be overcome by scaﬀolding the inquiry process along a spectrum of progression. This so-called model progression allows learners to start with a simpliﬁed version of the simulation; complexity is gradually increased by introducing new variables or features during the course of the learningprocess ( De Jong & Van Joolingen, 1998 ). In Co-Lab, the ﬂoors within a building represent the various levels of complexity. To illustrate, model progression in thewater management building develops from a simulation of a water tank, througha real water tank (accessible via a remote lab), to an advanced simulation of poldersand rivers that includes tidal movement, rainfall, and pumping stations. While model progression enables learners to employ existing self-regulatory skills, it does not cater for the use of unmastered skills. To provide the latter type of sup- port, speciﬁc features or tools are implemented in the learning environment. The sec-tions below discuss measures for promoting planning, monitoring and evaluation. 4.4. Planning Planning is supported in Co-Lab by outlining the steps learners should take dur- ing each phase of the inquiry process. This type of suppsort is particularly useful for learners with lower levels of self-regulation ( Vermunt, 1998 ), and research suggests that Co-Lab /C213s target audience matches this proﬁle. Manlove and Lazonder (2004) re- port that Co-Lab users between the ages of 15 and 17 hardly engaged in planningand frequently expressed their ignorance of the general approach to the learningtask. This observation prompted the development of a fully speciﬁed planning toolcalled the Process Coordinator (see Fig. 2 ). It contains a series of goals and subgoals that guide learners through the stages of
(see Fig. 2 ). It contains a series of goals and subgoals that guide learners through the stages of the inquiry process. Each goal statementcomes with a description stating what learners should do to accomplish that goal, and one or more hints that answer frequently asked questions. The purpose of this design is to promote self-regulation which in turn will yield higher knowledge gains.Attempts to validate this assumption are in progress. As learners /C213self-regulatory skills are expected to improve, planning support can be gradually faded. In keeping with the building metaphor, the Process Coordinatorcontains fewer and less explicit directions on higher ﬂoors. Fading may occurby removing the subgoals, the descriptions, and the hints in any preferred order.Finally, also the top level goals can be removed, leaving an open, unspeciﬁed plan- ning tool. The Process Coordinator thus provides a temporary support structure which can be considered another instance of model progression. 4.4.1. Monitoring In the monitoring phase, learners engage in control and observation of both their comprehension, attention, and performance in relation to the goals set during theanalysis phase. Monitoring can be triggered internally (e.g., learners spontaneouslyconsider their approach to the inquiry task) and externally (e.g., inconsistent resultsW.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 677
prompt learners to check the simulation /C213s settings). It is therefore somewhat diﬃcult to anticipate exactly when monitoring will (or should) occur. This in turn compli- cates the design of speciﬁc monitoring support – at least, without an intelligent tutor-ing system (cf. Veermans, 2002 ). Monitoring is supported by giving overviews of the learner /C213s actions in the envi- ronment ( De Jong & Van Joolingen, 1998 ). While Co-Lab does not provide ready- made overviews, it does facilitate learners in compiling overviews themselves. In theProcess Coordinator, learners can make notes associated to the goals present, andreview these on a History page. Learners also can tick oﬀ goals they consider completed. 4.4.2. Evaluation Evaluation pertains to a judgment of learning outcome as well as the learning process. While there often is no clear-cut distinction between evaluation and moni-toring, Scho¨n (1991) diﬀerentiates between reﬂection on action from reﬂection in ac- tion. Reﬂection in action pertains to monitoring activities, whereas reﬂection onaction can be likened to evaluation activities which occur at ‘‘certain stopping points’’ during an activity, often at the end of the learning process. Process displays and process prompts have been used to promote evaluation of learners engaged in discovery learning ( Lin, Hmelo, Kinzer, & Secules, 1999 ). A process display shows explicitly to learners what they are doing to solve a task. Inlearning environments this is often a trace or history of student actions. Processprompts give learners the opportunity ‘‘ ...to explain and evaluate what they do Fig. 2. Screenshot of the Process Coordinator.678 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
before during and after problem solving acts’’ ( Lin et al., 1999 ). These prompts are usually in the form of questions posed to the student by the learning environment.Lin and Lehman /C213s (1999) study of diﬀerent prompt types found that prompting learners to justify their reasoning directed learner /C213s attention more to understanding ‘‘when, why, and how to employ experiment design principles and strategies’’ (p. 837). This in turn enabled better transfer of their understanding to novel problems. Co-Lab utilizes both process displays and process prompts via the multiple views within the Process Coordinator. In the goal view, a process model is supplied to thelearners in the form of goals and subgoals which gives learners an overview of theprocess they should engage in. The process prompts are supplied in the form of hintsper sub-goal and take a question and answer format. The history view within theprocess coordinator shows all learner actions organized under the goals provided.Finally both the history and the goal views are combined within the report view. It enables learners to see their goal progress within the goal view, along with the notes and products they have made in the history view. The report view also providesa template structure where learners write a report of their ﬁndings. The templatespeciﬁes report sections along with descriptions which assist learners in writing outwhat they have learned from their inquiries and what they have learned about theprocess of inquiry. 5. Facilitating modeling Mental models are the internal representations we hold of our world. We use them to provide insight into how to reason over a particular problem, domain or sit-uation ( Jonassen, 1995 ). Assisting learners in acquiring appropriate mental models of physical systems is one of the main purposes of scientiﬁc discovery learning. Com-puter modeling has been recognized as an eﬀective method to facilitate mental modeldevelopment. By building an executable domain
as an eﬀective method to facilitate mental modeldevelopment. By building an executable domain model, learners externalize and test their conceptions of the variables in the simulation. The role of the model thus is to house domain knowledge and to be a vehicle for students /C213understanding and con- ceptual change ( Jonassen, Strobel, & Gottdenker, in press ). There are many types of modeling formalisms, from concept map notations to text based modeling found, for example, in goal tree structures (e.g., Lo¨hner, Van Joolingen, & Savelsbergh, 2003 ). When reasoning about the continuous physical sys- tems found in water management and green house gasses however, systems dynamicsmodeling appears to be the most appropriate to represent these systems ( Frederiksen & White, 1998; Jackson, Stratford, Krajcik, & Soloway, 1996 ). Such models reﬂect the dynamic nature of physical systems, by allowing simulation, envisioning the con-sequences of all direct and indirect relationships between variables in a time-depend-ent system. The use of generic variable types such as stocks, constants and auxiliariesprovide learners with ‘‘mini’’ mental models of how to think about variables andtheir relationships in the system. The Co-Lab environment contains a Model Editortool which allows learners to construct systems dynamic models of the phenomenadisplayed in the simulation.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 679
When learners construct a model, they tend to go through four stages: (1) model sketching, (2) model speciﬁcation, (3) data interpretation, and (4) model revision(cf.Hogan & Thomas, 2001 ). As Co-Lab perceives modeling as an integral part of scientiﬁc inquiry, the stages in the modeling process are closely related to thephases of the inquiry learning process identiﬁed by Njoo and De Jong (1993) .I n the orientation phase, learners sketch a model outline to express their initial under- standing of the phenomena from the simulation. In the hypothesis phase, this sketchis transformed into a runnable model by specifying the relations between the varia-bles in the model. During data interpretation, learners compare their model to datafrom the simulation which, during the conclusion phase, feeds their decision to revisethe model. Given the intertwined nature of inquiry and modeling, much of the support which has been explained in the previous sections also applies to supporting modeling activities. The sections below therefore present the support learners can use for model building per se. 5.1. Support for model sketching During problem analysis, learners can make a situation drawing to express their initial mental model and understanding of a domain ( Forbus, Carney, Harris, & Sherin, 2001; Oliver & Hannaﬁn, 2001 ). The sketch often serves to scaﬀold the com- plexities found in simulation-based inquiry learning, where learners have to unravel various, simultaneously interacting cause/eﬀect relationships ( Jackson et al., 1996 ). Co-Lab supports model sketching through a graphical modeling tool which allowslearners to build an icon-based model structure (see Fig. 3 ). Additionally, learners are supported within Co-Lab in learning systems dynamic modeling via a tutorialand model editor help ﬁles. 5.1.1. Support for model speciﬁcation In model speciﬁcation, learners deﬁne the relations between variables in their model. These relations initially represent a learner /C213s --- graphs, or entering mathematical formulas (see Fig. 4 ). As variable and property identiﬁcation progresses across a qualitative to quantitative spectrum ( Njoo & De Jong, 1993 ), learners are prompted to specify their model accordingly, using qualita- tive relations to specify their hypotheses and quantitative relations to express insightsderived from the simulation. 5.2. Support for data interpretation and model revision Running a model to generate data is the primary means of model testing and revising ( Forbus et al., 2001; Frederiksen & White, 1998 ). The data resulting from model runs need to be interpreted by the learner to establish how well the data fromtheir model match with the results from the simulation. This intrinsic feedback amodel can give is an important factor also in assisting students in evaluating their domain understanding ( Jackson et al., 1996 ). To facilitate the comparison of data between simulation runs and model runs, Co- Lab facilitates the display of the output of the experiments with the simulation orremote lab and the learner-constructed model in a single graph (see Fig. 1 ). Addi- tionally a curve ﬁtting tool can help the learners in constructing a model by perform-ing a statistical analysis on the data collected. When learners select this option, thesystem calculates the goodness of ﬁt between the model output (as shown in thegraph) and a given theoretical distribution (e.g., a curvilinear relationship). Examining and interpreting model output is essential for understanding scientiﬁc phenomena. Yet research shows that students use model output sparingly, usually onlyat the end of a modeling session to check if obtained results match their initial expecta-tions ( Hogan & Thomas, 2001; Stratford, Krajcik, & Soloway, 1997 ). Modeling should Fig. 3. Screenshot of the Model Editor.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 681
relations between variables in their model. These relations initially represent a learner /C213s assumptions of how variables interact; later the relations represent the learner /C213s insights derived from the simu- lation. According to Lo¨hner et al. (2003) , qualitative speciﬁcations are appropriate during the initial stages of the modeling process when learners still lack a clearunderstanding of the model they are building. In fact scientists in practice oftenstart with a qualitatively expressed model ( White & Frederiksen, 1990 ). By qual- itatively expressing relationships, learners begin to construct a bridge between their initial mental model of the system (as found in the model sketch) and the target model ( Jackson et al., 1996 ). Quantitative, formula-based speciﬁcations are more useful for the later part of the modeling process, when the model is ﬁnalized.As both forms of representation play a distinct role in the modeling process, learn-ers are best supported by a modeling tool that accommodates a mixedrepresentation. Co-Lab /C213s Model Editor was designed according to these guidelines. It allows learners to specify their model by selecting pre-deﬁned qualitative relations, drawing680 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
involve dynamic iterations between examining output and revising models. As learners generally fail to spontaneously adopt such an iterative approach, the learning environ-ment should prompt them to do so. In Co-Lab, these prompts are oﬀered in the ProcessCoordinator, fully integrated with the directions for systematic experimentation. 6. Facilitating collaboration In order for students to ‘‘act like scientists’’, a discovery learning environment should support working in collaborative groups. An additional advantage of collab-oration is that it promotes higher achievement than individual learning strategies(e.g., Lou et al., 1996 ). Other studies have shown that this eﬀect transfers to discov- ery learning. Paired students generally are more successful in discovering scientiﬁcmechanisms than single students (e.g., Okada & Simon, 1997; Teasley, 1995 ). These studies further demonstrate that the superiority of student pairs is attributable topeer interaction. Collaboration increases the likelihood that learners engage in the type of talk that supports learning, such as asking and answering of questions, rea- soning and conﬂict resolution. Collaboration also promotes regulation of the learning task. In a study by Laz- onder (submitted) , pairs of students showed relatively higher proportions of self- regulatory activities than single students. More speciﬁcally, dyads exhibited a richerrepertoire of strategies to solve problems. They were also more proﬁcient in monitor-ing each other /C213s actions which facilitated early detection and correction of errors. The results for evaluation also diﬀered in favor of the dyads. They crosschecked ini- tial answers more frequently and modiﬁed initially incorrect responses more than twice as often. Further research is needed to determine if these eﬀects generalize todiscovery learning. These studies however, focused on face-to-face collaboration. Comparisons of computer-mediated and face-to-face collaboration suggest that
collaboration. Comparisons of computer-mediated and face-to-face collaboration suggest that computer-mediatedcollaboration is characterized by a number of deﬁciencies. A number of studies have,for instance, found that face-to-face dyads attain higher performance scores than Fig. 4. Qualitative, graphical, and quantitative speciﬁcation of relations in a model.682 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
students who collaborate online (e.g., Salminen, Marttunen, & Laurinen, 2003; Van der Meijden & Veenman, in press ). Face-to-face dyads also have more prolonged dis- cussions on the learning task; communication in the computer-mediated dyads ismore directed at coordinating eﬀorts, operating the communication tool, andexpressing emotions. Together, these ﬁndings indicate that computer-mediated collaboration can pro- mote scientiﬁc discovery learning, but that collaboration itself should be promotedfor learners to take full advantage of each others presence. This implication is relevantto Co-Lab, as this environment is designed for synchronous online collaboration, per-mitting learners to work together in real time while being geographically dispersed. Co-Lab allows for this type of collaboration by providing several means of sup- port for collaboration. The Co-Lab environment is a shared space, in which learnerscan see each others actions and to which each learner can contribute. Also Co-Lab includes a communication channel based on chat, as well as a place for storing com- monly built objects as well as and functions that increase social presence. Thesekinds of support for collaboration are elaborated below. Although such supportive features are available (e.g., reﬂective notebooks, collab- orative concept maps, communication widgets), their eﬃcacy in synchronous onlinecollaboration has not yet been assessed. Yet empirical validation is needed becauseCo-Lab /C213s target audience is familiar with online communication technologies. To illustrate, Lazonder, Wilhelm, and Ootes (2003) examined the eﬃcacy of sentence openers to foster peer interaction. Sentence openers are pre-deﬁned opening phrases students can readily select from a menu in their chat tool. The students in this studyhardly used sentence openers, a result that was attributable to their chat experience.Students were accustomed to typing chat messages and maintained in this chat style,being unwilling or
were accustomed to typing chat messages and maintained in this chat style,being unwilling or unable to adopt an alternative way to create messages. This lead tothe decision that sentence openers should not be included in Co-Lab. 6.1. Support for student interaction Peer-to-peer collaboration encourages students to articulate their thoughts, which in turn has a facilitative eﬀect on achievement and regulation. Co-Lab enables socialinteraction through a chat tool. Consistent with the building metaphor, the chat isroom-speciﬁc, which means that by default messages can only be read in the roomin which they were sent. Usability tests revealed that this division was too strict as it impeded the learning dis- course. Learners speciﬁcally asked for an ‘‘intercom’’ to contact group members in dif- ferent rooms. This functionality was implemented in the form of the ‘‘Send to ﬂoor’’ button. By pressing this button, the unsent chat message becomes visible in every room. 6.2. Support for shared knowledge building Constructing shared knowledge is the ultimate goal of collaborative learning. This goal has two important consequences for the tools in collaborative discovery learn-ing environments. One is that shared knowledge must be represented explicitly soW.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 683 --- learners can see the objects they are working on and talking about. Learners should thus be oﬀered a joint space to post their ideas, hypotheses, models and so on. Thesecond implication is that the learners /C213multiple perspectives should be integrated. This means that the tools should allow learners to manipulate the objects representedin the joint space. The notion of shared workspaces was central to the design of Co-Lab. In a way, Co- Lab itself is one shared workspace: the environment holds no private tools or spaces, soeverything a learner does is readily visible to and editable by his/her group members. Toensure that the collaboration proceeds in an orderly way, Co-Lab introduces the notionofcontrol . In each room only one learner (the ‘‘leader’’) can perform all actions; the others are merely allowed to do reversible actions that have no permanent trace inthe learning environment. What is considered to be reversible action can be controlledon a tool-by-tool and even a button-by-button basis. An example of a reversible action is choosing a plot of a speciﬁc variable out of an existing data set, i.e. opening a speciﬁc view on existing data. An irreversible action would be creating a new data set, or mak-ing changes to a model. Learners can request and pass on control to each other bymeans of a dedicated control tool, which uses a traﬃc light metaphor. 6.3. Support for social presence Face-to-face collaboration is dominated by social presence (a sense of being to- gether) where individuals can interact eﬀortlessly. As online collaboration is weak in social presence, designated tools are needed to increase learner /C213s sense of being together (Kirschner, 2002 ). Co-Lab /C213s Locator tool allows learners to check which group mem- bers are online and which room they are in. Manlove and Lazonder (2004) showed that learners use this tool frequently to see if group members have entered the environmentor joined them when changing rooms. The Locator also served to
members have entered the environmentor joined them when changing rooms. The Locator also served to trace group memberswho did not contribute to the ongoing chat discussion. 7. Co-Lab evaluation studies Apart from initial speciﬁcation studies and usability studies mentioned above, that lead to modiﬁcations of Co-Lab design, Co-Lab has been evaluated with learn-ers in two formative and two summative evaluation studies. The results of the form-ative evaluation studies also contributed to the ﬁnal product. The current section willbrieﬂy describe these studies. Full reports are available in Lazonder (2004) . As Co- Lab is a large comprehensive system, evaluation studies have had to focus on speciﬁc aspects of it, rather than evaluating the whole system. The ﬁrst formative evaluation study focused on learners /C213general impressions of the system. The goal was to evaluate whether students are able to use the Co-Labenvironment in its natural state. To this end learners ( N= 43) went through a full Co-Lab session, although the model in this session was relatively simple. Learners /C213 actions were logged and they ﬁlled in a questionnaire after completing the session.This lead to a number of remarks regarding the room metaphor and workﬂow within684 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
the environment: in a complex environment like Co-Lab students indicate a high need for transparency (knowing what is the current task, knowing where co-workersare, knowing where information can be found) as well as a need to improve themeans for collaborative tasks, such as planning and encouraging. This lead tochanges in communication (chat across rooms) and to the availability of the process coordinator in every room. The second formative evaluation study examined eﬃciency in terms of how stu- dents work with Co-Lab with minimal guidance from evaluators or the environment.The goal was to (1) describe working patterns and group approaches to the learningtask and to obtain base-line data which shows how students are or are not regulatingtheir inquiry. Students ( N= 39) worked in a minimally guided Co-Lab environment on a simple inquiry task. It was found that in the early stages of the session, the labwork prevailed; learners showed a preference for the lab room, only later on mode- ling and more systematic experimentation were taken on by the learners. With respect to regulation it was found that most regulation eﬀort went toward regulatingthe collaborative process, rather than the learning task. Again this supports the sug-gestion to integrate tools designed to promote learners /C213regulation into rooms where the inquiry task is being performed. In the ﬁrst summative evaluation study, the collaboration as envisioned by Co- Lab was compared to a face-to-face collaboration setting. The purpose was to inves-tigate in what way the on-line communication mode in Co-Lab would inﬂuence the task attainment in Co-Lab, compared to the more traditional face-to-face mode. Stu- dents ( N= 40) worked on two Co-Lab ﬂoors, where the ﬁrst served an introductory purpose. The analysis focused mainly on the modeling task. It was found that therewas no signiﬁcant diﬀerence in product of learning (the quality of the created mod-els), but there were diﬀerences in process. Face-to-face
learning (the quality of the created mod-els), but there were diﬀerences in process. Face-to-face working students showedmore superﬁcial behavior and actions of specifying model values had a negative ef-fect on learning product, which was not the case for the on-line collaborating dyads.This indicates that the two collaborative modes are essentially diﬀerent, and that the on-line collaborative mode employed by Co-Lab can promote deeper processing. Finally, the second summative study speciﬁcally evaluated the process coordina- tor that is present in Co-Lab. The study compared two groups of students ( N= 61), one working with a pre-ﬁlled process coordinator, and one for which this tool wasleft empty, and for which students had to ﬁll it themselves. The group with the ﬁlledprocess coordinator performed more planning actions and used the process coordi-nator more often than the other group. This study supports research indicating thestudents need scaﬀolds such as the process coordinator in order to fully beneﬁt from the complexity and richness of the data provided for them, when working in environ- ments like Co-Lab. 8. Conclusion In this contribution, the Co-Lab learning environment served as a vehicle to express the authors /C213views on collaborative discovery learning. Co-Lab /C213s initialW.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 685
design was based on insights gleaned from instructional theory and empirical re- search. Usability tests were conducted to improve the user-friendliness of the envi-ronment and the intuitiveness of its tools. Formative and summative evaluationswere also performed to assess Co-Labs potential to foster collaborative inquirylearning. As an environment, Co-Lab is suitable to provide a means for an integrated ap- proach for collaboration, modeling and inquiry. Co-Lab is the ﬁrst environment inwhich these three learning modes are brought together and integrated. Co-Lab /C213s structure keeps the complexity of the environment within reasonable limits, asmay be inferred from the unguided activities that learners have undertaken. Alsospeciﬁc instructional support, such as the process coordinator, qualitative modelingand the oﬀering of challenging assignments provides a means for engaging studentsin an authentic inquiry context. The studies performed with Co-Lab indicate that the way of oﬀering support is well on track, however more research is needed to understand Co-Lab and to make surethat Co-Lab will eventually be used in classrooms. Research is needed and plannedinto the assessment of learning in collaborative inquiry environments: how can we as-sess learning products such as inquiry skills, deeper domain knowledge and skills forcollaboration. Although attempts have been made to measure knowledge from dis-covery learning ( Swaak & De Jong, 1996 ) more research is needed to cover the full range of knowledge types that express a learner /C213s proﬁciency in inquiry and modeling. In order to bring Co-Lab to actual education more research and development is also needed. As such Co-Lab represents a developmental end point towards collab-orative inquiry, but a path leading to this end point has not yet been laid out. Teach-ers will not accept the use of an integrated system like Co-Lab immediately, thus animplementation trajectory needs to be carefully designed. A follow-up
Co-Lab immediately, thus animplementation trajectory needs to be carefully designed. A follow-up project, calledReCoIL (Resoirces for Collaborative Inquiry Learning) is currently underway inproviding such an implementation strategy. Acknowledgements The work reported here was supported by the European Community under the Information Society Technology (IST) School of Tomorrow programme (contractIST-2000-25035). The authors are solely responsible for the content of this article.It does not represent the opinion of the European Community, and the EuropeanCommunity is not responsible for any use that might be made of data appearing therein. Partners in the Co-Lab project are: the University of Twente, the Univer- sity of Amsterdam, The University of Murcia, Studio TEOS, the Leibnitz Institutfur Pa ¨dagogische Naturwissenschaften. The authors thank the following persons who contributed to the Co-Lab system and project: Anjo Anjewierden, Jasper Be-deaux, Martin Beugel, Thorsten Bell, Davide Biolghini, Ulrich Bosler, Ben Bruid-egom, Alberto Ceccarelli, Miguel Celdran, Marijn van Eupen, Leendert vanGastel, Jose van Gelderen, Stefano Gobbi, Simone Lo ¨hner, Ernesto Martin, Ton ˜i Martı ´nez Carreras, Eduardo Martinez Gracia, Laura Miani, Tina Miggiano, Man-686 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
uel Mora, Maarten Pieters, Sascha Schanze, Jakob Sikken, Patrick Sins, Antonio Gomez Skarmeta, Roberto de Souza, Peter Uylings, Pascal Wilhelm, ThiloWu¨nschler. References Brown, J. S., Collins, A., & Duguid, P. (1989). Situated cognition and the culture of learning. Educational Researcher, 18 (1), 32–42. Bruner, J. (1961). The act of discovery. Harvard Educational Review, 31 , 21–32. De Jong, T., & Van Joolingen, W. R. (1998). Scientiﬁc discovery learning with computer simulations of conceptual domains. Review of Educational Research, 68 , 179–202. Dunbar, K. (2001). What scientiﬁc thinking reveals about the nature of cognition. In K. Cowley, C. D. Schum, & T. Okada (Eds.), Designing for science: Implications from everyday, classroom and professional settings (pp. 47–72). Mahwah: Erlbaum. Elshout, J. J. (1987). Problem solving and education. In E. de Corte, H. Lodewijks, R. Parmentier, & P. Span (Eds.), Learning and instruction (pp. 259–273). Oxford: Pergamon. Forbus, K., Carney, K., Harris, R. & Sherin, B. (2001). A qualitative modeling environment for middle- school students: a progress report. In Proceedings of the 15th international workshop on qualitative reasoning (QR01) . Available: http://qrg.northwestern.edu/papers/papers.htm . Frederiksen, J. R., & White, B. Y. (1998). Teaching and learning generic modeling and reasoning skills. Interactive Learning Environments, 5 , 33–51. Gijlers, H., & De Jong, T. (2004). Het ondersteunen van samenwerkend ontdekkende leren in een simulatie omgeving [Supporting collaborative discovery learning in a simulation environment] . Paper presented at the Onderwijs Research Dagen 2004, Utrecht, The Netherlands. Available: http://edu.fss.uu.nl/ord/ . Hogan, K., & Thomas, D. (2001). Cognitive comparisons of students /C213systems modeling in ecology. Journal of Science Education and Technology, 10 , 75–96. Jackson, S., Stratford, S. J., Krajcik, J. S., & Soloway, E. (1996). Making systems dynamics modeling accessible to pre-college --- Lou, Y., Abrami, P. C., Spence, J. C., Poulson, C., Chambers, B., & /C212d Apollonia, S. (1996). Within-class grouping: a meta-analysis. Review of Educational Research, 66 , 423–458. Manlove, S. A. & Lazonder, A. W. (2004). Self-regulation and collaboration in a discovery learning environment . Paper presented at the ﬁrst EARLI Metacognition SIG conference, Amsterdam. Available: http://users.edte.utwente.nl/lazonder/homepage/NL/Publijst.html . Njoo, M., & De Jong, T. (1993). Supporting exploratory learning by oﬀering structured overviews of hypotheses. In D. Towne, T. de Jong, & H. Spada (Eds.), Simulation-based experiential learning (pp. 207–225). Berlin: Springer-Verlag. Okada, T., & Simon, H. A. (1997). Collaborative discovery in a scientiﬁc domain. Cognitive Science, 21 , 109–146. Oliver, K., & Hannaﬁn, M. (2001). Developing and reﬁning mental models in open-ended learning environments: a case study. Educational Technology Research and Development, 49 , 5–32. Penner, D. E. (2001). Cognition, computers, and synthetic science: Building knowledge and meaning through modeliling. Review of Research in Education, 25 , 1–37. Salminen, T., Marttunen, M. & Laurinen, L. (2003). The quality of secondary school students /C213 argumentative dialogue: comparing face-to-face and chat debates . Paper presented at the 10th EARLI Conference, August 26–30, Padova, Italy. Schauble, L., Klopfer, L., & Raghavan, K. (1991). Students /C213transitions from an engineering to a science model of experimentation. Journal of Research in Science Teaching, 28 , 859–882. Scho¨n, D. (1991). The reﬂective practitioner: How professionals think in action . Hants: Ashgate. Stratford, S. J., Krajcik, J. & Soloway, E. (1997, March). Secondary students /C213dynamic modeling processes: Analyzing, reasoning about, synthesizing, and testing models of stream ecosystems . Paper presented at the annual meeting of the American Educational Research Association, Chicago, IL. Swaak, J., & de Jong, T. de (1996).
Krajcik, J. S., & Soloway, E. (1996). Making systems dynamics modeling accessible to pre-college science students. Interactive Learning Environments, 4 , 233–257. Jonassen, D. H. (1995). Operationalizing mental models: strategies for assessing mental models to support meaningful learning and design-supportive learning environments. In J. L. Schnase & E. L. Cunnius(Eds.), Proceedings of Cscl /C21395: The ﬁrst international conference on computer support for collaborative learning: October 17–20, 1995 . Bloomington, Indiana, USA: Indiana University. Available: http:// www.ittheory.com/jonassen2.htm . Jonassen, D. H., Strobel, J. & Gottdenker, J. (in press). Modeling for meaningful learning. In R. Floden, K. McKevitt (Eds.), Technology for meaningful learning . New York: Teacher /C213s College Press. Kirschner, P. A. (2002). Can we support CSCL? Educational, social and technological aﬀordances for learning . Inaugural address, Heerlen, The Netherlands: Open Universiteit Nederland. Kluwe, R. H. (1982). Cognitive knowledge and executive control: Metacognition. In D. R. Griﬀen (Ed.), Animal mind–human mind (pp. 201–224). New York: Springer-Verlag. Lazonder, A. W. (submitted). Do two heads search better than one? Eﬀects of student collaboration on Web search behavior and search outcomes . Lazonder, A. W. (Ed.) (2004). Report on evaluation studies, collaborative laboratories for Europe . Deliverable D8, project report. Enschede, The Netherlands: University of Twente. Lazonder, A. W., Wilhelm, P., & Ootes, S. A. W. (2003). Using sentence openers to foster student interaction in computer-mediated learning environments. Computers and Education, 41 , 291–308. Lin, X., Hmelo, C., Kinzer, C. K., & Secules, T. J. (1999). Designing technology to support reﬂection. Educational Technology Research and Development, 47 (3), 43–62. Lin, X., & Lehman, J. D. (1999). Supporting learning of variable control in a computer based biology environment: eﬀects of prompting college students to
variable control in a computer based biology environment: eﬀects of prompting college students to reﬂect on their own thinking. Journal of Research in Science Teaching, 36 , 837–858. Lo¨hner, S., Van Joolingen, W. R., & Savelsbergh, E. R. (2003). The eﬀect of external representation on constructing computer models of complex phenomena. Instructional Science, 31 , 395–418.W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688 687
of the American Educational Research Association, Chicago, IL. Swaak, J., & de Jong, T. de (1996). Measuring intuitive knowledge in science: the what-if test. Studies in Educational Evaluation, 22 , 341–362. Teasley, S. D. (1995). The role of talk in children /C213s peer collaborations. Developmental Psychology, 31 , 207–220. Van der Meijden, H. & Veenman, S. (2004). Face-to-face versus computer-mediated communication in a primary school setting. Computers in Human Behavior . doi: 10.1016/j.chb.2004.10.005 . Van Joolingen, W. R., & De Jong, T. (1993). Exploring a domain through a computer simulation: traversing variable and relation space with the help of a hypothesis scratchpad. In D. Towne, T. deJong, & H. Spada (Eds.), Simulation-based experiential learning (pp. 191–206). Berlin: Springer-Verlag. Van Joolingen, W. R., & De Jong, T. (2003). SimQuest, authoring educational simulations. In T. Murray, S. Blessing, & S. Ainsworth (Eds.), Authoring tools for advanced technology learning environments: Toward cost-eﬀective adaptive, interactive, and intelligent educational software (pp. 1–31). Dordrecht: Kluwer. Veermans, K. (2002). Intelligent support for discovery learning . Unpublished doctoral dissertation, Enschede, University of Twente, The Netherlands. Vermunt, J. (1998). The regulation of constructive learning processes. British Journal of Educational Psychology, 68 , 149–171. White, B., & Frederiksen, J. R. (1990). Causal model progressions as a foundation for intelligent learning environments. Artiﬁcial Intelligence, 42 , 99–157.688 W.R. van Joolingen et al. / Computers in Human Behavior 21 (2005) 671–688
El artículo "Co-Lab: investigación y desarrollo de un entorno de aprendizaje en línea para el descubrimiento científico colaborativo" presenta un enfoque detallado sobre los desafíos de diseño en entornos de aprendizaje colaborativo para el descubrimiento científico. Se centra en Co-Lab, un entorno en el que los estudiantes pueden experimentar a través de simulaciones y laboratorios remotos, y expresar su comprensión en un modelo informático ejecutable. Se discuten procesos de colaboración, investigación y modelado, y se propone una agenda de investigación para el aprendizaje colaborativo de descubrimiento con Co-Lab.

El artículo destaca la importancia de abordar los desafíos de diseño en entornos de aprendizaje colaborativo para el descubrimiento científico y ofrece una visión detallada de cómo Co-Lab aborda estos desafíos. Se discuten temas clave como el aprendizaje colaborativo, el aprendizaje por indagación, los entornos de aprendizaje y el modelado dinámico. Se destaca la importancia de apoyar los procesos de colaboración, investigación y modelado en entornos de aprendizaje en línea y se propone una agenda de investigación para seguir avanzando en este campo.

El artículo también aborda la importancia de la reflexión y la colaboración en entornos de aprendizaje colaborativo para el descubrimiento. Se discute cómo Co-Lab apoya la construcción de hipótesis, el diseño de experimentos, la interpretación de datos y la evaluación en el proceso de aprendizaje. Se destaca la importancia de la monitorización y evaluación en el proceso de aprendizaje, así como la necesidad de herramientas y sistemas inteligentes para facilitar estos procesos en entornos de simulación como Co-Lab.

En resumen, el artículo proporciona una visión detallada de cómo Co-Lab aborda los desafíos de diseño en entornos de aprendizaje colaborativo para el descubrimiento científico. Se discuten temas clave como la colaboración, la investigación, el modelado y la evaluación, y se propone una agenda de investigación para seguir avanzando en este campo. El artículo destaca la importancia de apoyar los procesos de aprendizaje colaborativo y de descubrimiento en entornos en línea y ofrece una visión integral de cómo Co-Lab puede ser utilizado como un entorno efectivo para el aprendizaje colaborativo en ciencias.
